{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Description\n",
        "This is the final notebook which I used for my final submission to the competition. It generated 0.805 AMEX public score where 1st place contender scored 0.809. The order of steps are as following:\n",
        "\n",
        "\n",
        "*   Load and Preprocess\n",
        "*   Feature Engineering\n",
        "*   Ensemble Models\n",
        "*   Autotuning\n",
        "\n",
        "Note that models has been built based on the tuning results regardless of the order of the steps in the notebook.\n",
        "\n",
        "For further inital models and analysis, please refer to the other notebooks. "
      ],
      "metadata": {
        "id": "_PpcKFLmOo3X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and preprocess"
      ],
      "metadata": {
        "id": "Yj1yZq9vsJxK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load packages and raw data"
      ],
      "metadata": {
        "id": "G7q6INvXQZlx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import gzip, pickle\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "nMibiISb9dY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the data from drive \n",
        "df_train=pd.read_pickle('/content/drive/MyDrive/int_train.pkl', compression='gzip')\n",
        "train_labels=pd.read_csv('/content/drive/MyDrive/train_labels.csv')\n",
        "df_test=pd.read_pickle('/content/drive/MyDrive/int_test.pkl',compression='gzip')"
      ],
      "metadata": {
        "id": "wRizRXRQV0Si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seperate numeric and categorical variables\n",
        "# Function for describing both numeric and categorical variables (by Uri Smashnov)\n",
        "def describe_more(df,normalize_ind=False, weight_column=None, skip_columns=[], dropna=True):\n",
        "    var = [] ; l = [] ; t = []; unq =[]; min_l = []; max_l = [];\n",
        "    assert isinstance(skip_columns, list), \"Argument skip_columns should be list\"\n",
        "    if weight_column is not None:\n",
        "        if weight_column not in list(df.columns):\n",
        "            raise AssertionError('weight_column is not a valid column name in the input DataFrame')\n",
        "      \n",
        "    for x in df:\n",
        "        if x in skip_columns:\n",
        "            pass\n",
        "        else:\n",
        "            var.append( x )\n",
        "            uniq_counts = len(pd.value_counts(df[x],dropna=dropna))\n",
        "            uniq_counts = len(pd.value_counts(df[x], dropna=dropna)[pd.value_counts(df[x],dropna=dropna)>0])\n",
        "            l.append(uniq_counts)\n",
        "            t.append( df[ x ].dtypes )\n",
        "            min_l.append(df[x].apply(str).str.len().min())\n",
        "            max_l.append(df[x].apply(str).str.len().max())\n",
        "            if weight_column is not None and x not in skip_columns:\n",
        "                df2 = df.groupby(x).agg({weight_column: 'sum'}).sort_values(weight_column, ascending=False)\n",
        "                df2['authtrans_vts_cnt']=((df2[weight_column])/df2[weight_column].sum()).round(2)\n",
        "                unq.append(df2.head(n=100).to_dict()[weight_column])\n",
        "            else:\n",
        "                df_cat_d = df[x].value_counts(normalize=normalize_ind,dropna=dropna).round(decimals=2)\n",
        "                df_cat_d = df_cat_d[df_cat_d>0]\n",
        "                #unq.append(df[x].value_counts().iloc[0:100].to_dict())\n",
        "                unq.append(df_cat_d.iloc[0:100].to_dict())\n",
        "            \n",
        "    levels = pd.DataFrame( { 'A_Variable' : var , 'Levels' : l , 'Datatype' : t ,\n",
        "                             'Min Length' : min_l,\n",
        "                             'Max Length': max_l,\n",
        "                             'Level_Values' : unq} )\n",
        "    #levels.sort_values( by = 'Levels' , inplace = True )\n",
        "    return levels\n"
      ],
      "metadata": {
        "id": "L0BHniLbMWQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', None)\n",
        "described=describe_more(df_train.iloc[:50000,:])"
      ],
      "metadata": {
        "id": "j_q0q33xBMvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Drop redundant features"
      ],
      "metadata": {
        "id": "758YLVQ-IMuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.groupby(['D_103','D_107'])['customer_ID'].agg('count').reset_index(name='n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "J-Yb34N4HtfN",
        "outputId": "54c26887-cb08-4aa7-8f23-5ade90aa657c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    D_103  D_107        n\n",
              "0      -1     -1   101548\n",
              "1       0      0  2919859\n",
              "2       1      1  1875253\n",
              "3       1      2   520153\n",
              "4       1      3    93165\n",
              "5       1      4    16661\n",
              "6       1      5     3344\n",
              "7       1      6      827\n",
              "8       1      7      369\n",
              "9       1      8      101\n",
              "10      1      9       34\n",
              "11      1     10       49\n",
              "12      1     11       14\n",
              "13      1     12        3\n",
              "14      1     13       28\n",
              "15      1     14        9\n",
              "16      1     15        9\n",
              "17      1     17       11\n",
              "18      1     18        1\n",
              "19      1     19        5\n",
              "20      1     20        6\n",
              "21      1     21        2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e818b676-0fb8-4bba-a394-cb538e481186\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>D_103</th>\n",
              "      <th>D_107</th>\n",
              "      <th>n</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>101548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2919859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1875253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>520153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>93165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>16661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e818b676-0fb8-4bba-a394-cb538e481186')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e818b676-0fb8-4bba-a394-cb538e481186 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e818b676-0fb8-4bba-a394-cb538e481186');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.groupby(['D_139','D_145'])['customer_ID'].agg('count').reset_index(name='n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "R_kWIA9VH96e",
        "outputId": "a2dbe245-eb27-495f-fb9a-18496ea511e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    D_139  D_145        n\n",
              "0      -1     -1   101548\n",
              "1       0      0  4485483\n",
              "2       1      1   370084\n",
              "3       1      2   177905\n",
              "4       1      3    82127\n",
              "5       1      4    73007\n",
              "6       1      5    46174\n",
              "7       1      6    40625\n",
              "8       1      7    28340\n",
              "9       1      8    26476\n",
              "10      1      9    18839\n",
              "11      1     10    17743\n",
              "12      1     11    12514\n",
              "13      1     12    11250\n",
              "14      1     13     8071\n",
              "15      1     14     6552\n",
              "16      1     15     5484\n",
              "17      1     16     4439\n",
              "18      1     17     3424\n",
              "19      1     18     2388\n",
              "20      1     19     1962\n",
              "21      1     20     1450\n",
              "22      1     21     1223\n",
              "23      1     22      961\n",
              "24      1     23      777\n",
              "25      1     24      451\n",
              "26      1     25      357\n",
              "27      1     26      379\n",
              "28      1     27      299\n",
              "29      1     28      183\n",
              "30      1     29      234\n",
              "31      1     30      130\n",
              "32      1     31      140\n",
              "33      1     32       88\n",
              "34      1     33       46\n",
              "35      1     34       58\n",
              "36      1     35       89\n",
              "37      1     36       25\n",
              "38      1     37        5\n",
              "39      1     38        4\n",
              "40      1     39        9\n",
              "41      1     40       11\n",
              "42      1     41       21\n",
              "43      1     42        7\n",
              "44      1     43       10\n",
              "45      1     44        8\n",
              "46      1     45        7\n",
              "47      1     46       11\n",
              "48      1     47        8\n",
              "49      1     50       12\n",
              "50      1     52        8\n",
              "51      1     53        5"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4707449c-0dba-4611-aaff-885e919fe734\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>D_139</th>\n",
              "      <th>D_145</th>\n",
              "      <th>n</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>101548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4485483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>370084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>177905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>82127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>73007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>46174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>40625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>28340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>26476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>18839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>17743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>12514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>11250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>8071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>6552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>5484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>4439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>3424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>2388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>1962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>1450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>1223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "      <td>961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "      <td>777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "      <td>299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>1</td>\n",
              "      <td>31</td>\n",
              "      <td>140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>1</td>\n",
              "      <td>33</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>1</td>\n",
              "      <td>34</td>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>1</td>\n",
              "      <td>36</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>1</td>\n",
              "      <td>40</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>1</td>\n",
              "      <td>41</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>1</td>\n",
              "      <td>43</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>1</td>\n",
              "      <td>44</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>1</td>\n",
              "      <td>45</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>1</td>\n",
              "      <td>46</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>1</td>\n",
              "      <td>52</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>1</td>\n",
              "      <td>53</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4707449c-0dba-4611-aaff-885e919fe734')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4707449c-0dba-4611-aaff-885e919fe734 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4707449c-0dba-4611-aaff-885e919fe734');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "D_139 and D_103 are redundant because their values can be explained by other variables. S_2 is also redundant because it is the time of the entry, does not include too much information."
      ],
      "metadata": {
        "id": "dTHEaJUXISgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # suppose features with less than 10 levels are categorical\n",
        "# categorical=[]\n",
        "# numeric=[]\n",
        "# for [col,level] in described[['A_Variable','Levels']].values:\n",
        "#   if col not in ['S_2','D_139','D_103','customer_ID']:\n",
        "#     if level<10:\n",
        "#       categorical.append(col)\n",
        "#     else: numeric.append(col)\n",
        "# features=categorical+numeric\n",
        "# print(categorical)"
      ],
      "metadata": {
        "id": "-ut34fyWRR6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features=[col for col in df_train.columns if col not in ['S_2','D_139','D_103','customer_ID']]"
      ],
      "metadata": {
        "id": "Xfv_UaEDuQZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing and feature engineering"
      ],
      "metadata": {
        "id": "x8ttrxyYr8a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# shift to positive values\n",
        "for col in features:\n",
        "  min_val=np.nanmin(df_train[col])\n",
        "  df_train[col]=df_train[col]-min_val+1\n",
        "  df_test[col]=df_test[col]-min_val+1"
      ],
      "metadata": {
        "id": "55dWCxzcSH1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a summary functions map\n",
        "col_map={}\n",
        "for col in features:\n",
        "  col_map[col]=[np.nanmean, np.nanstd, np.nanmin, np.nanmax, 'last']\n",
        "#Summarize the train data for each customer\n",
        "train_num_agg = df_train.groupby('customer_ID').agg(col_map)\n",
        "train_num_agg.columns = ['_'.join(x) for x in train_num_agg.columns]\n",
        "train_num_agg.columns = [col if col[-5:]!='_last' else col[:-5] for col in train_num_agg.columns]\n",
        "\n",
        "#Summarize the test data for each customer\n",
        "test_num_agg = df_test.groupby('customer_ID').agg(col_map)\n",
        "test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n",
        "test_num_agg.columns = [col if col[-5:]!='_last' else col[:-5] for col in test_num_agg.columns]"
      ],
      "metadata": {
        "id": "zGvrgjNtSW2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate trend variables for train data (percent change):  (mean(last_3_months)-mean(first_3_months))/mean(first_3_months)\n",
        "col_map={}\n",
        "for col in features:\n",
        "  col_map[col]=[np.nanmean]\n",
        "\n",
        "#Summarize the last 3 rows of data for each customer\n",
        "train_last = df_train.groupby('customer_ID').tail(3)\n",
        "train_last = train_last.groupby('customer_ID').agg(col_map)\n",
        "train_last.columns = ['_'.join(x) for x in train_last.columns]\n",
        "\n",
        "#Summarize the first 3 rows of data for each customer\n",
        "train_first = df_train.groupby('customer_ID').head(3)\n",
        "train_first = train_first.groupby('customer_ID').agg(col_map)\n",
        "train_first.columns = ['_'.join(x) for x in train_first.columns]\n",
        "\n",
        "#create trend variables that show the percentage change between first 3 and last 3 months\n",
        "train_trend=pd.DataFrame(index=train_first.index)\n",
        "for col in train_first.columns:\n",
        "  train_trend[col+'trend']=(train_last[col]-train_first[col])/(train_first[col]+0.001)\n",
        "#---------------------------------------------------------------------------------------#\n",
        "# repeat the above calculations for test data\n",
        "#Summarize the last 3 rows of data for each customer\n",
        "test_last = df_test.groupby('customer_ID').tail(3)\n",
        "test_last = test_last.groupby('customer_ID').agg(col_map)\n",
        "test_last.columns = ['_'.join(x) for x in test_last.columns]\n",
        "\n",
        "#Summarize the first 3 rows of data for each customer\n",
        "test_first = df_test.groupby('customer_ID').head(3)\n",
        "test_first = test_first.groupby('customer_ID').agg(col_map)\n",
        "test_first.columns = ['_'.join(x) for x in test_first.columns]\n",
        "\n",
        "#create trend variables that show the percentage change between first 3 and last 3 months\n",
        "test_trend=pd.DataFrame(index=test_first.index)\n",
        "for col in test_first.columns:\n",
        "  test_trend[col+'trend']=(test_last[col]-test_first[col])/(test_first[col]+0.001)"
      ],
      "metadata": {
        "id": "C2-0TmvEUjg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove the trend features that have to many missing values\n",
        "for col in train_trend.columns:\n",
        "  if train_trend[col].isna().sum()>20000:\n",
        "    train_trend.drop([col],inplace=True,axis=1)\n",
        "train_trend.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJImSWKOV6wI",
        "outputId": "e969bbc3-e971-4e87-ad7f-8f4b00278a63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(458913, 152)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels=train_labels.set_index('customer_ID',drop=True)\n",
        "train_combined=pd.concat([train_num_agg,train_trend,labels],axis=1)\n",
        "del train_num_agg\n",
        "del train_first\n",
        "del train_last\n",
        "del train_labels\n",
        "del train_trend"
      ],
      "metadata": {
        "id": "NPrPME-6gUMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_combined=pd.concat([test_num_agg,test_trend],axis=1)\n",
        "del test_num_agg\n",
        "del test_first\n",
        "del test_last\n",
        "del test_trend\n",
        "test_combined.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gS6bRTEyaJwZ",
        "outputId": "52bf356f-4e00-4de2-8cd2-9feb4daa5d72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(924621, 1116)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create new features\n",
        "def feature_eng(a):\n",
        "  # create the numeric features based on the eda analysis\n",
        "  a['bp12'] = a['B_1']-a['P_2']\n",
        "  a['pb34'] = a['P_3']/a['B_4']\n",
        "  a['rs']=a['R_1']*a['S_3'] # risk is weighted by the spending\n",
        "  a['rd']=a['S_3']*a['D_39']\n",
        "  a['br']=a['B_1']*a['R_1']\n",
        "  a['bd']=a['B_1']*a['D_41']\n",
        "  a['p/bsr']=a['P_2']/((a['B_3']+a['S_3'])*a['R_1'])\n",
        "\n",
        "  # some addition features\n",
        "  a['ps']=a['P_2']/a['S_3'] # payment compared to spending\n",
        "  a['rp']=a['R_1']/a['P_2'] # current risk scaled by the last payment\n",
        "  a['bps']=a['B_3']+a['S_3']-a['P_2'] #spending and balance excess\n",
        "  print('new numerical features created...')\n",
        "  #boolean\n",
        "  a['r12']=a['R_1']>a['R_2'] # change in risk (assuming it is time series)\n",
        "  a['r23']=a['R_2']>a['R_3']\n",
        "  a['p23']=a['P_2']>a['P_3'] # change in payment\n",
        "  a['b12']=a['B_1']>a['B_2'] # change in balance\n",
        "  print('new categorical features created...')\n",
        "\n",
        "  feature_num=['bp12','pb34','rs','rd','br','bd','p/bsr','ps','rp','bps']\n",
        "  feature_cat=['r12','r23','p23','b12']\n",
        "  for col in feature_cat:\n",
        "    a[col]=a[col].astype('int')\n",
        "  return a\n",
        "#train_combined=feature_eng(train_combined)\n",
        "test_combined=feature_eng(test_combined)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLBM1HLohU38",
        "outputId": "f9342beb-875f-43ab-903a-da46939f7fac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new numerical features created...\n",
            "new categorical features created...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function for getting lag 1 \n",
        "def get_lag_1(data, num_features):\n",
        "    df1 = []\n",
        "    customer_ids = []\n",
        "    for customer_id, df in tqdm(data.groupby(['customer_ID'])):\n",
        "        # if only one row, then lag is nan\n",
        "        if len(df)==1:\n",
        "          diff_df1=np.array([np.nan for i in df[num_features].values[0]])\n",
        "          df1.append(diff_df1)\n",
        "          customer_ids.append(customer_id)\n",
        "        else:\n",
        "          # Get the lag\n",
        "          diff_df1 = df[num_features].values[0].astype(np.float32)\n",
        "          # Append to lists\n",
        "          df1.append(diff_df1)\n",
        "          customer_ids.append(customer_id)\n",
        "    # create lag_frame\n",
        "    df1 = pd.DataFrame(df1, columns = [col + '_lag1' for col in df[num_features].columns])\n",
        "    # Add customer id\n",
        "    df1['customer_ID'] = customer_ids\n",
        "    return df1\n",
        "\n",
        "data=df_train.groupby('customer_ID').tail(2).set_index('customer_ID',drop=True).sort_index()\n",
        "del df_train\n",
        "# get lag_1\n",
        "lag_train=get_lag_1(data, features)\n",
        "lag_train=lag_train.set_index('customer_ID',drop=True).sort_index()\n",
        "\n",
        "\n",
        "# append lags to the train_combined\n",
        "train_combined=pd.concat([train_combined,lag_train],axis=1)\n",
        "del data\n",
        "del lag_train"
      ],
      "metadata": {
        "id": "HEh1epHdkVUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=df_test.groupby('customer_ID').tail(2).set_index('customer_ID',drop=True).sort_index()\n",
        "del df_test\n",
        "# get lag_1\n",
        "lag_test=get_lag_1(data, features)\n",
        "lag_test=lag_test.set_index('customer_ID',drop=True).sort_index()\n",
        "\n",
        "# append lags to the test_combined\n",
        "test_combined=pd.concat([test_combined,lag_test],axis=1)\n",
        "del data\n",
        "del lag_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sERycm73eobZ",
        "outputId": "a489fd27-5c31-4e4a-95d3-64d23f4cf0eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 924621/924621 [12:10<00:00, 1265.39it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create last-mean difference columns for train data\n",
        "for col in features:\n",
        "  train_combined[col+'_diff_mean']=train_combined[col]-train_combined[col+'_nanmean']\n",
        "# save data to pickle object\n",
        "train_combined.to_pickle('train_amex.pkl',compression='gzip')\n",
        "train=pd.read_pickle('/content/drive/MyDrive/train_amex.pkl', compression='gzip')"
      ],
      "metadata": {
        "id": "7wlhImyc2NqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create last-mean difference columns for test data\n",
        "for col in features:\n",
        "  test_combined[col+'_diff_mean']=test_combined[col]-test_combined[col+'_nanmean']\n",
        "\n",
        "columns=[col for col in train.columns if col!='target']\n",
        "\n",
        "test_combined=test_combined[columns]\n",
        "print(train.shape, test_combined.shape)\n",
        "\n",
        "# save data to pickle object\n",
        "test_combined.to_pickle('test_amex.pkl',compression='gzip')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MioRpMuiem8a",
        "outputId": "c9f0d082-f102-4fc3-bda6-d47c60cb9285"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(458913, 1469) (924621, 1468)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deafault prediction models"
      ],
      "metadata": {
        "id": "KcMCbsQyPhFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "predictors=[col for col in train.columns if col!='target']\n",
        "x_train, x_val, y_train, y_val=train_test_split(train[predictors], train[['target']], test_size=0.2, random_state=1221)\n",
        "print(x_train.shape,x_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyoWCBe38aPr",
        "outputId": "871d431c-5cde-4fb4-f207-7f112a808a47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(367130, 1468) (91783, 1468)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create the custom metric fot the lgb model \n",
        "def amex(preds, train_data) -> float:\n",
        "    y_true=train_data.get_label()\n",
        "    y_pred = 1. / (1. + np.exp(-preds))\n",
        "\n",
        "    def amex_metric_mod(y_true, y_pred):\n",
        "\n",
        "        labels     = np.transpose(np.array([y_true, y_pred]))\n",
        "        labels     = labels[labels[:, 1].argsort()[::-1]]\n",
        "        weights    = np.where(labels[:,0]==0, 20, 1)\n",
        "        cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
        "        top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
        "\n",
        "        gini = [0,0]\n",
        "        for i in [1,0]:\n",
        "            labels         = np.transpose(np.array([y_true, y_pred]))\n",
        "            labels         = labels[labels[:, i].argsort()[::-1]]\n",
        "            weight         = np.where(labels[:,0]==0, 20, 1)\n",
        "            weight_random  = np.cumsum(weight / np.sum(weight))\n",
        "            total_pos      = np.sum(labels[:, 0] *  weight)\n",
        "            cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n",
        "            lorentz        = cum_pos_found / total_pos\n",
        "            gini[i]        = np.sum((lorentz - weight_random) * weight)\n",
        "\n",
        "        return 0.5 * (gini[1]/gini[0] + top_four)\n",
        "    return 'amex', amex_metric_mod(y_true,y_pred), True"
      ],
      "metadata": {
        "id": "v6VL2-MspiTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "lgb_train = lgb.Dataset(x_train, label=y_train,\n",
        "                         free_raw_data=False)\n",
        "lgb_eval = lgb.Dataset(x_val, label=y_val, reference=lgb_train,\n",
        "                        free_raw_data=False)\n",
        "\n",
        "params = {'bagging_fraction': 0.65,\n",
        "          'objective':'binary',\n",
        "          # 'metric':'binary_logloss',\n",
        "          # 'pos_bagging_fraction':0.33,\n",
        "          # 'neg_bagging_fraction':1,\n",
        "          # 'feature_fraction_bynode':0.5,\n",
        "          'boosting_type':'dart',\n",
        "          # 'drop_rate':0.2,\n",
        "          # 'bagging_freq': 10,\n",
        "          \"metric\": \"None\",\n",
        "          \"first_metric_only\": True,\n",
        "          'feature_fraction': 0.25,\n",
        "          # 'lambda_l1': 0.0001,\n",
        "          # 'lambda_l2': 5,\n",
        "          'learning_rate': 0.01,\n",
        "          #  'max_depth': 30,\n",
        "          #'min_child_samples': 190,\n",
        "          'min_data_in_leaf': 80,\n",
        "          # 'min_split_gain': 7e-05,\n",
        "          'num_leaves': 80,\n",
        "          'seed':55,\n",
        "          'n_jobs':-1}\n",
        "my_model = lgb.train(   \n",
        "                    params, \n",
        "                    num_boost_round=7000,\n",
        "                    train_set=lgb_train,\n",
        "                    valid_sets=[lgb_eval,lgb_train],\n",
        "                    feval=amex,\n",
        "                    early_stopping_rounds=250, verbose_eval=50\n",
        "                    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "os7rgumPBQyZ",
        "outputId": "18b10097-28ab-498d-d09d-406c78378950"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50]\ttraining's amex: 0.767773\tvalid_0's amex: 0.759148\n",
            "[100]\ttraining's amex: 0.770962\tvalid_0's amex: 0.76273\n",
            "[150]\ttraining's amex: 0.773067\tvalid_0's amex: 0.763997\n",
            "[200]\ttraining's amex: 0.774634\tvalid_0's amex: 0.764884\n",
            "[250]\ttraining's amex: 0.775792\tvalid_0's amex: 0.766422\n",
            "[300]\ttraining's amex: 0.777234\tvalid_0's amex: 0.767799\n",
            "[350]\ttraining's amex: 0.77837\tvalid_0's amex: 0.768245\n",
            "[400]\ttraining's amex: 0.779773\tvalid_0's amex: 0.769297\n",
            "[450]\ttraining's amex: 0.780439\tvalid_0's amex: 0.76974\n",
            "[500]\ttraining's amex: 0.781191\tvalid_0's amex: 0.76968\n",
            "[550]\ttraining's amex: 0.782318\tvalid_0's amex: 0.77095\n",
            "[600]\ttraining's amex: 0.783453\tvalid_0's amex: 0.77095\n",
            "[650]\ttraining's amex: 0.784842\tvalid_0's amex: 0.772259\n",
            "[700]\ttraining's amex: 0.786388\tvalid_0's amex: 0.772907\n",
            "[750]\ttraining's amex: 0.787985\tvalid_0's amex: 0.773222\n",
            "[800]\ttraining's amex: 0.789016\tvalid_0's amex: 0.774346\n",
            "[850]\ttraining's amex: 0.789991\tvalid_0's amex: 0.775108\n",
            "[900]\ttraining's amex: 0.791506\tvalid_0's amex: 0.775913\n",
            "[950]\ttraining's amex: 0.792382\tvalid_0's amex: 0.77665\n",
            "[1000]\ttraining's amex: 0.793684\tvalid_0's amex: 0.777358\n",
            "[1050]\ttraining's amex: 0.79525\tvalid_0's amex: 0.778821\n",
            "[1100]\ttraining's amex: 0.796502\tvalid_0's amex: 0.779518\n",
            "[1150]\ttraining's amex: 0.797825\tvalid_0's amex: 0.780013\n",
            "[1200]\ttraining's amex: 0.799376\tvalid_0's amex: 0.78054\n",
            "[1250]\ttraining's amex: 0.800787\tvalid_0's amex: 0.781429\n",
            "[1300]\ttraining's amex: 0.802232\tvalid_0's amex: 0.782114\n",
            "[1350]\ttraining's amex: 0.80341\tvalid_0's amex: 0.78273\n",
            "[1400]\ttraining's amex: 0.804663\tvalid_0's amex: 0.78343\n",
            "[1450]\ttraining's amex: 0.805957\tvalid_0's amex: 0.783832\n",
            "[1500]\ttraining's amex: 0.807008\tvalid_0's amex: 0.784234\n",
            "[1550]\ttraining's amex: 0.807998\tvalid_0's amex: 0.784476\n",
            "[1600]\ttraining's amex: 0.809116\tvalid_0's amex: 0.785217\n",
            "[1650]\ttraining's amex: 0.809923\tvalid_0's amex: 0.78569\n",
            "[1700]\ttraining's amex: 0.810764\tvalid_0's amex: 0.786205\n",
            "[1750]\ttraining's amex: 0.811775\tvalid_0's amex: 0.786237\n",
            "[1800]\ttraining's amex: 0.812635\tvalid_0's amex: 0.78641\n",
            "[1850]\ttraining's amex: 0.813844\tvalid_0's amex: 0.786899\n",
            "[1900]\ttraining's amex: 0.814824\tvalid_0's amex: 0.78741\n",
            "[1950]\ttraining's amex: 0.816086\tvalid_0's amex: 0.788126\n",
            "[2000]\ttraining's amex: 0.817284\tvalid_0's amex: 0.788119\n",
            "[2050]\ttraining's amex: 0.818275\tvalid_0's amex: 0.787913\n",
            "[2100]\ttraining's amex: 0.819153\tvalid_0's amex: 0.788416\n",
            "[2150]\ttraining's amex: 0.820258\tvalid_0's amex: 0.789087\n",
            "[2200]\ttraining's amex: 0.8209\tvalid_0's amex: 0.78923\n",
            "[2250]\ttraining's amex: 0.821829\tvalid_0's amex: 0.78921\n",
            "[2300]\ttraining's amex: 0.822571\tvalid_0's amex: 0.789373\n",
            "[2350]\ttraining's amex: 0.823512\tvalid_0's amex: 0.789465\n",
            "[2400]\ttraining's amex: 0.824463\tvalid_0's amex: 0.78984\n",
            "[2450]\ttraining's amex: 0.825428\tvalid_0's amex: 0.789832\n",
            "[2500]\ttraining's amex: 0.826401\tvalid_0's amex: 0.789554\n",
            "[2550]\ttraining's amex: 0.827359\tvalid_0's amex: 0.789687\n",
            "[2600]\ttraining's amex: 0.828213\tvalid_0's amex: 0.790053\n",
            "[2650]\ttraining's amex: 0.829491\tvalid_0's amex: 0.789845\n",
            "[2700]\ttraining's amex: 0.830219\tvalid_0's amex: 0.790398\n",
            "[2750]\ttraining's amex: 0.83092\tvalid_0's amex: 0.790608\n",
            "[2800]\ttraining's amex: 0.831829\tvalid_0's amex: 0.790654\n",
            "[2850]\ttraining's amex: 0.832626\tvalid_0's amex: 0.790992\n",
            "[2900]\ttraining's amex: 0.833525\tvalid_0's amex: 0.791266\n",
            "[2950]\ttraining's amex: 0.83446\tvalid_0's amex: 0.791231\n",
            "[3000]\ttraining's amex: 0.835553\tvalid_0's amex: 0.791277\n",
            "[3050]\ttraining's amex: 0.836311\tvalid_0's amex: 0.79167\n",
            "[3100]\ttraining's amex: 0.83732\tvalid_0's amex: 0.791599\n",
            "[3150]\ttraining's amex: 0.838361\tvalid_0's amex: 0.791406\n",
            "[3200]\ttraining's amex: 0.839184\tvalid_0's amex: 0.791351\n",
            "[3250]\ttraining's amex: 0.839946\tvalid_0's amex: 0.79145\n",
            "[3300]\ttraining's amex: 0.840686\tvalid_0's amex: 0.79154\n",
            "[3350]\ttraining's amex: 0.841622\tvalid_0's amex: 0.791421\n",
            "[3400]\ttraining's amex: 0.842408\tvalid_0's amex: 0.791818\n",
            "[3450]\ttraining's amex: 0.843084\tvalid_0's amex: 0.791925\n",
            "[3500]\ttraining's amex: 0.843813\tvalid_0's amex: 0.791823\n",
            "[3550]\ttraining's amex: 0.844716\tvalid_0's amex: 0.792006\n",
            "[3600]\ttraining's amex: 0.845384\tvalid_0's amex: 0.792159\n",
            "[3650]\ttraining's amex: 0.845975\tvalid_0's amex: 0.792274\n",
            "[3700]\ttraining's amex: 0.846746\tvalid_0's amex: 0.792462\n",
            "[3750]\ttraining's amex: 0.847664\tvalid_0's amex: 0.792276\n",
            "[3800]\ttraining's amex: 0.848299\tvalid_0's amex: 0.792273\n",
            "[3850]\ttraining's amex: 0.849197\tvalid_0's amex: 0.792595\n",
            "[3900]\ttraining's amex: 0.849986\tvalid_0's amex: 0.792824\n",
            "[3950]\ttraining's amex: 0.850833\tvalid_0's amex: 0.793032\n",
            "[4000]\ttraining's amex: 0.85181\tvalid_0's amex: 0.793448\n",
            "[4050]\ttraining's amex: 0.852788\tvalid_0's amex: 0.793436\n",
            "[4100]\ttraining's amex: 0.853824\tvalid_0's amex: 0.79337\n",
            "[4150]\ttraining's amex: 0.854747\tvalid_0's amex: 0.793563\n",
            "[4200]\ttraining's amex: 0.855572\tvalid_0's amex: 0.793499\n",
            "[4250]\ttraining's amex: 0.856573\tvalid_0's amex: 0.79352\n",
            "[4300]\ttraining's amex: 0.857315\tvalid_0's amex: 0.793736\n",
            "[4350]\ttraining's amex: 0.858105\tvalid_0's amex: 0.793772\n",
            "[4400]\ttraining's amex: 0.859045\tvalid_0's amex: 0.794295\n",
            "[4450]\ttraining's amex: 0.859623\tvalid_0's amex: 0.793957\n",
            "[4500]\ttraining's amex: 0.860584\tvalid_0's amex: 0.794034\n",
            "[4550]\ttraining's amex: 0.861324\tvalid_0's amex: 0.794216\n",
            "[4600]\ttraining's amex: 0.862176\tvalid_0's amex: 0.794103\n",
            "[4650]\ttraining's amex: 0.862939\tvalid_0's amex: 0.794117\n",
            "[4700]\ttraining's amex: 0.863692\tvalid_0's amex: 0.794551\n",
            "[4750]\ttraining's amex: 0.864783\tvalid_0's amex: 0.794567\n",
            "[4800]\ttraining's amex: 0.865516\tvalid_0's amex: 0.7945\n",
            "[4850]\ttraining's amex: 0.866487\tvalid_0's amex: 0.794593\n",
            "[4900]\ttraining's amex: 0.867254\tvalid_0's amex: 0.794627\n",
            "[4950]\ttraining's amex: 0.868124\tvalid_0's amex: 0.794805\n",
            "[5000]\ttraining's amex: 0.868959\tvalid_0's amex: 0.795045\n",
            "[5050]\ttraining's amex: 0.86967\tvalid_0's amex: 0.795056\n",
            "[5100]\ttraining's amex: 0.870501\tvalid_0's amex: 0.79502\n",
            "[5150]\ttraining's amex: 0.871497\tvalid_0's amex: 0.795245\n",
            "[5200]\ttraining's amex: 0.872328\tvalid_0's amex: 0.795409\n",
            "[5250]\ttraining's amex: 0.873102\tvalid_0's amex: 0.795189\n",
            "[5300]\ttraining's amex: 0.874001\tvalid_0's amex: 0.794905\n",
            "[5350]\ttraining's amex: 0.87478\tvalid_0's amex: 0.795036\n",
            "[5400]\ttraining's amex: 0.87578\tvalid_0's amex: 0.794987\n",
            "[5450]\ttraining's amex: 0.876514\tvalid_0's amex: 0.795187\n",
            "[5500]\ttraining's amex: 0.877501\tvalid_0's amex: 0.795454\n",
            "[5550]\ttraining's amex: 0.878379\tvalid_0's amex: 0.795566\n",
            "[5600]\ttraining's amex: 0.879267\tvalid_0's amex: 0.79524\n",
            "[5650]\ttraining's amex: 0.880071\tvalid_0's amex: 0.795313\n",
            "[5700]\ttraining's amex: 0.880716\tvalid_0's amex: 0.795279\n",
            "[5750]\ttraining's amex: 0.881496\tvalid_0's amex: 0.795195\n",
            "[5800]\ttraining's amex: 0.882174\tvalid_0's amex: 0.795242\n",
            "[5850]\ttraining's amex: 0.882864\tvalid_0's amex: 0.795127\n",
            "[5900]\ttraining's amex: 0.883659\tvalid_0's amex: 0.795571\n",
            "[5950]\ttraining's amex: 0.884421\tvalid_0's amex: 0.795638\n",
            "[6000]\ttraining's amex: 0.885173\tvalid_0's amex: 0.795681\n",
            "[6050]\ttraining's amex: 0.885679\tvalid_0's amex: 0.795649\n",
            "[6100]\ttraining's amex: 0.886435\tvalid_0's amex: 0.795715\n",
            "[6150]\ttraining's amex: 0.886957\tvalid_0's amex: 0.795674\n",
            "[6200]\ttraining's amex: 0.887646\tvalid_0's amex: 0.795535\n",
            "[6250]\ttraining's amex: 0.88848\tvalid_0's amex: 0.795601\n",
            "[6300]\ttraining's amex: 0.889308\tvalid_0's amex: 0.795475\n",
            "[6350]\ttraining's amex: 0.890108\tvalid_0's amex: 0.795672\n",
            "[6400]\ttraining's amex: 0.890717\tvalid_0's amex: 0.795467\n",
            "[6450]\ttraining's amex: 0.891354\tvalid_0's amex: 0.795451\n",
            "[6500]\ttraining's amex: 0.892094\tvalid_0's amex: 0.795558\n",
            "[6550]\ttraining's amex: 0.892918\tvalid_0's amex: 0.795667\n",
            "[6600]\ttraining's amex: 0.893479\tvalid_0's amex: 0.795861\n",
            "[6650]\ttraining's amex: 0.894117\tvalid_0's amex: 0.796079\n",
            "[6700]\ttraining's amex: 0.894648\tvalid_0's amex: 0.795892\n",
            "[6750]\ttraining's amex: 0.895351\tvalid_0's amex: 0.79604\n",
            "[6800]\ttraining's amex: 0.896066\tvalid_0's amex: 0.79613\n",
            "[6850]\ttraining's amex: 0.896773\tvalid_0's amex: 0.796156\n",
            "[6900]\ttraining's amex: 0.897371\tvalid_0's amex: 0.796135\n",
            "[6950]\ttraining's amex: 0.898137\tvalid_0's amex: 0.796394\n",
            "[7000]\ttraining's amex: 0.898793\tvalid_0's amex: 0.796564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "# save model\n",
        "joblib.dump(my_model, 'lgb.pkl')\n",
        "# load model\n",
        "gbm_pickle = joblib.load('lgb.pkl')"
      ],
      "metadata": {
        "id": "bs_awnySvVer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test=pd.read_pickle('/content/drive/MyDrive/test_amex.pkl', compression='gzip')\n",
        "import lightgbm as lgb\n",
        "lgb_holdout=lgb.Dataset(test,free_raw_data=False)\n"
      ],
      "metadata": {
        "id": "0QiAaoNMMVzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in tqdm(test.columns):\n",
        "  if test[col].dtype in ['float32','float64']:\n",
        "    test[col]=test[col].astype('float16')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfKOQqlvOOJ6",
        "outputId": "9064149e-0ccc-4f4d-856e-1edab52540d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1468/1468 [10:07<00:00,  2.42it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the notebook crashes when predicting using full test dataset, hence we predict the full dataset in 10 batches\n",
        "preds=[]\n",
        "start,end=0,100000\n",
        "for i in tqdm(range(9)):\n",
        "  preds=preds+list(gbm_pickle.predict(test.iloc[start:end,:]))\n",
        "  start=end\n",
        "  end=end+10**5\n",
        "preds=preds+list(gbm_pickle.predict(test.iloc[start:,:]))"
      ],
      "metadata": {
        "id": "Xr3aiVB8OICo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the submission file\n",
        "submission=pd.DataFrame(test.index).set_index('customer_ID',drop=True)\n",
        "submission['prediction']=preds\n",
        "submission.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "a7NV9D2VW2DU",
        "outputId": "107920e2-c9cb-415b-a12a-f50441c87e97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    prediction\n",
              "customer_ID                                                   \n",
              "00000469ba478561f23a92a868bd366de6f6527a684c9a2...    0.038573\n",
              "00001bf2e77ff879fab36aa4fac689b9ba411dae63ae397...    0.001761\n",
              "0000210045da4f81e5f122c6bde5c2a617d03eef67f82c5...    0.050199\n",
              "00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976cf...    0.268645\n",
              "00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9a...    0.853875"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-61f55d1c-ac22-4bba-810c-734cbc4f234a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>customer_ID</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>00000469ba478561f23a92a868bd366de6f6527a684c9a2e78fb826dcac3b9b7</th>\n",
              "      <td>0.038573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00001bf2e77ff879fab36aa4fac689b9ba411dae63ae397d4263dafa1daedef5</th>\n",
              "      <td>0.001761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0000210045da4f81e5f122c6bde5c2a617d03eef67f82c5e400fc98e7bd43ce8</th>\n",
              "      <td>0.050199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976cf6e56734528702d694</th>\n",
              "      <td>0.268645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9a4693dd914fca22557</th>\n",
              "      <td>0.853875</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61f55d1c-ac22-4bba-810c-734cbc4f234a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-61f55d1c-ac22-4bba-810c-734cbc4f234a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-61f55d1c-ac22-4bba-810c-734cbc4f234a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission[\"prediction\"].to_csv(\"submission_first.csv\",index=True)"
      ],
      "metadata": {
        "id": "yv2x5nEgX4c5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models with different parameters"
      ],
      "metadata": {
        "id": "BiHAOh4BNuan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "lgb_train = lgb.Dataset(x_train, label=y_train,\n",
        "                         free_raw_data=False)\n",
        "lgb_eval = lgb.Dataset(x_val, label=y_val, reference=lgb_train,\n",
        "                        free_raw_data=False)\n",
        "\n",
        "params = {'bagging_fraction': 0.65,\n",
        "          'objective':'binary',\n",
        "          # 'metric':'binary_logloss',\n",
        "          # 'pos_bagging_fraction':0.33,\n",
        "          # 'neg_bagging_fraction':1,\n",
        "          # 'feature_fraction_bynode':0.5,\n",
        "          'boosting_type':'dart',\n",
        "          # 'drop_rate':0.2,\n",
        "          # 'bagging_freq': 10,\n",
        "          \"metric\": \"None\",\n",
        "          \"first_metric_only\": True,\n",
        "          'feature_fraction': 0.15,\n",
        "          # 'lambda_l1': 0.0001,\n",
        "          # 'lambda_l2': 5,\n",
        "          'learning_rate': 0.008,\n",
        "          #  'max_depth': 30,\n",
        "          #'min_child_samples': 190,\n",
        "          'min_data_in_leaf': 150,\n",
        "          # 'min_split_gain': 7e-05,\n",
        "          'num_leaves': 60,\n",
        "          'seed':55,\n",
        "          'n_jobs':-1}\n",
        "gbm2 = lgb.train(   \n",
        "                    params, \n",
        "                    num_boost_round=16000,\n",
        "                    train_set=lgb_train,\n",
        "                    valid_sets=[lgb_eval,lgb_train],\n",
        "                    feval=amex,\n",
        "                    early_stopping_rounds=250, verbose_eval=0\n",
        "                    )\n",
        "#callbacks=[lgb.reset_parameter(learning_rate = [0.03]*1500 + [0.02]*1500+[0.01]*2000+[0.0085]*3000+[0.007]*4000+[0.005]*4000) ]"
      ],
      "metadata": {
        "id": "EnaRY3QwWqXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "lgb_train = lgb.Dataset(x_train, label=y_train,\n",
        "                         free_raw_data=False)\n",
        "lgb_eval = lgb.Dataset(x_val, label=y_val, reference=lgb_train,\n",
        "                        free_raw_data=False)\n",
        "\n",
        "params = {'bagging_fraction': 0.65,\n",
        "          'objective':'binary',\n",
        "          # 'metric':'binary_logloss',\n",
        "          # 'pos_bagging_fraction':0.33,\n",
        "          # 'neg_bagging_fraction':1,\n",
        "          # 'feature_fraction_bynode':0.5,\n",
        "          'boosting_type':'dart',\n",
        "          'drop_rate':0.25,\n",
        "          'skip_drop':0.2,\n",
        "          'drop_seed':123,\n",
        "          # 'bagging_freq': 10,\n",
        "          \"metric\": \"None\",\n",
        "          \"first_metric_only\": True,\n",
        "          'feature_fraction': 0.1,\n",
        "          # 'lambda_l1': 0.0001,\n",
        "          # 'lambda_l2': 5,\n",
        "          # 'learning_rate': 0.008,\n",
        "          #  'max_depth': 30,\n",
        "          #'min_child_samples': 190,\n",
        "          'min_data_in_leaf': 200,\n",
        "          # 'min_split_gain': 7e-05,\n",
        "          'num_leaves': 150,\n",
        "          'seed':55,\n",
        "          'n_jobs':-1}\n",
        "gbm2 = lgb.train(   \n",
        "                    params, \n",
        "                    num_boost_round=18000,\n",
        "                    train_set=lgb_train,\n",
        "                    valid_sets=[lgb_eval,lgb_train],\n",
        "                    feval=amex,\n",
        "                    early_stopping_rounds=250, verbose_eval=0,\n",
        "                 callbacks=[lgb.reset_parameter(learning_rate = [0.03]*1500 + [0.02]*1500+[0.01]*3000+[0.0085]*4000+[0.0065]*4000+[0.004]*4000) ]\n",
        "                    )"
      ],
      "metadata": {
        "id": "ix92N0AUna1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "lgb_train = lgb.Dataset(x_train, label=y_train,\n",
        "                         free_raw_data=False)\n",
        "lgb_eval = lgb.Dataset(x_val, label=y_val, reference=lgb_train,\n",
        "                        free_raw_data=False)\n",
        "\n",
        "params = {'bagging_fraction': 0.65,\n",
        "          'objective':'binary',\n",
        "          # 'metric':'binary_logloss',\n",
        "          # 'pos_bagging_fraction':0.33,\n",
        "          # 'neg_bagging_fraction':1,\n",
        "          # 'feature_fraction_bynode':0.5,\n",
        "          'boosting_type':'dart',\n",
        "          # 'drop_rate':0.2,\n",
        "          'bagging_freq': 20,\n",
        "          \"metric\": \"None\",\n",
        "          \"first_metric_only\": True,\n",
        "          'feature_fraction': 0.075,\n",
        "          # 'lambda_l1': 0.0001,\n",
        "          # 'lambda_l2': 5,\n",
        "          'learning_rate': 0.017,\n",
        "          #  'max_depth': 30,\n",
        "          #'min_child_samples': 190,\n",
        "          'min_data_in_leaf': 100,\n",
        "          # 'min_split_gain': 7e-05,\n",
        "          'num_leaves': 100,\n",
        "          'seed':55,\n",
        "          'n_jobs':-1}\n",
        "gbm2 = lgb.train(   \n",
        "                    params, \n",
        "                    num_boost_round=16000,\n",
        "                    train_set=lgb_train,\n",
        "                    valid_sets=[lgb_eval,lgb_train],\n",
        "                    feval=amex,\n",
        "                    early_stopping_rounds=250, verbose_eval=50\n",
        "                    )\n",
        "#callbacks=[lgb.reset_parameter(learning_rate = [0.03]*1500 + [0.02]*1500+[0.01]*2000+[0.0085]*3000+[0.007]*4000+[0.005]*4000) ]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtYnVQaUGoZr",
        "outputId": "2cf34e65-d009-4fe1-c137-6b5bc8523870"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50]\ttraining's amex: 0.768756\tvalid_0's amex: 0.761944\n",
            "[100]\ttraining's amex: 0.773956\tvalid_0's amex: 0.764768\n",
            "[150]\ttraining's amex: 0.777368\tvalid_0's amex: 0.767208\n",
            "[200]\ttraining's amex: 0.780546\tvalid_0's amex: 0.768791\n",
            "[250]\ttraining's amex: 0.783333\tvalid_0's amex: 0.771723\n",
            "[300]\ttraining's amex: 0.786087\tvalid_0's amex: 0.773301\n",
            "[350]\ttraining's amex: 0.78694\tvalid_0's amex: 0.773943\n",
            "[400]\ttraining's amex: 0.788637\tvalid_0's amex: 0.775385\n",
            "[450]\ttraining's amex: 0.790191\tvalid_0's amex: 0.77521\n",
            "[500]\ttraining's amex: 0.791747\tvalid_0's amex: 0.775775\n",
            "[550]\ttraining's amex: 0.79309\tvalid_0's amex: 0.776817\n",
            "[600]\ttraining's amex: 0.795042\tvalid_0's amex: 0.777887\n",
            "[650]\ttraining's amex: 0.796977\tvalid_0's amex: 0.778971\n",
            "[700]\ttraining's amex: 0.798839\tvalid_0's amex: 0.780063\n",
            "[750]\ttraining's amex: 0.800573\tvalid_0's amex: 0.780756\n",
            "[800]\ttraining's amex: 0.80262\tvalid_0's amex: 0.782099\n",
            "[850]\ttraining's amex: 0.804049\tvalid_0's amex: 0.782532\n",
            "[900]\ttraining's amex: 0.805725\tvalid_0's amex: 0.7834\n",
            "[950]\ttraining's amex: 0.807179\tvalid_0's amex: 0.784461\n",
            "[1000]\ttraining's amex: 0.80878\tvalid_0's amex: 0.785308\n",
            "[1050]\ttraining's amex: 0.811193\tvalid_0's amex: 0.785706\n",
            "[1100]\ttraining's amex: 0.813586\tvalid_0's amex: 0.786894\n",
            "[1150]\ttraining's amex: 0.81517\tvalid_0's amex: 0.787155\n",
            "[1200]\ttraining's amex: 0.817398\tvalid_0's amex: 0.787705\n",
            "[1250]\ttraining's amex: 0.819545\tvalid_0's amex: 0.7883\n",
            "[1300]\ttraining's amex: 0.821596\tvalid_0's amex: 0.789266\n",
            "[1350]\ttraining's amex: 0.823562\tvalid_0's amex: 0.789546\n",
            "[1400]\ttraining's amex: 0.825194\tvalid_0's amex: 0.790213\n",
            "[1450]\ttraining's amex: 0.826801\tvalid_0's amex: 0.790471\n",
            "[1500]\ttraining's amex: 0.828136\tvalid_0's amex: 0.790564\n",
            "[1550]\ttraining's amex: 0.829747\tvalid_0's amex: 0.790612\n",
            "[1600]\ttraining's amex: 0.831118\tvalid_0's amex: 0.790824\n",
            "[1650]\ttraining's amex: 0.832689\tvalid_0's amex: 0.790784\n",
            "[1700]\ttraining's amex: 0.833607\tvalid_0's amex: 0.791125\n",
            "[1750]\ttraining's amex: 0.834815\tvalid_0's amex: 0.791356\n",
            "[1800]\ttraining's amex: 0.836407\tvalid_0's amex: 0.79165\n",
            "[1850]\ttraining's amex: 0.837881\tvalid_0's amex: 0.791735\n",
            "[1900]\ttraining's amex: 0.839452\tvalid_0's amex: 0.792347\n",
            "[1950]\ttraining's amex: 0.840931\tvalid_0's amex: 0.792642\n",
            "[2000]\ttraining's amex: 0.842767\tvalid_0's amex: 0.793157\n",
            "[2050]\ttraining's amex: 0.844385\tvalid_0's amex: 0.793436\n",
            "[2100]\ttraining's amex: 0.846147\tvalid_0's amex: 0.793392\n",
            "[2150]\ttraining's amex: 0.847661\tvalid_0's amex: 0.792912\n",
            "[2200]\ttraining's amex: 0.848814\tvalid_0's amex: 0.792673\n",
            "[2250]\ttraining's amex: 0.850173\tvalid_0's amex: 0.793136\n",
            "[2300]\ttraining's amex: 0.851078\tvalid_0's amex: 0.79339\n",
            "[2350]\ttraining's amex: 0.852295\tvalid_0's amex: 0.793368\n",
            "[2400]\ttraining's amex: 0.853632\tvalid_0's amex: 0.793773\n",
            "[2450]\ttraining's amex: 0.854825\tvalid_0's amex: 0.793647\n",
            "[2500]\ttraining's amex: 0.85643\tvalid_0's amex: 0.794349\n",
            "[2550]\ttraining's amex: 0.857679\tvalid_0's amex: 0.794411\n",
            "[2600]\ttraining's amex: 0.859117\tvalid_0's amex: 0.794397\n",
            "[2650]\ttraining's amex: 0.860611\tvalid_0's amex: 0.793893\n",
            "[2700]\ttraining's amex: 0.862\tvalid_0's amex: 0.79464\n",
            "[2750]\ttraining's amex: 0.863162\tvalid_0's amex: 0.794415\n",
            "[2800]\ttraining's amex: 0.864481\tvalid_0's amex: 0.793994\n",
            "[2850]\ttraining's amex: 0.865474\tvalid_0's amex: 0.794687\n",
            "[2900]\ttraining's amex: 0.867141\tvalid_0's amex: 0.794704\n",
            "[2950]\ttraining's amex: 0.868871\tvalid_0's amex: 0.794806\n",
            "[3000]\ttraining's amex: 0.870316\tvalid_0's amex: 0.794459\n",
            "[3050]\ttraining's amex: 0.87167\tvalid_0's amex: 0.79425\n",
            "[3100]\ttraining's amex: 0.873063\tvalid_0's amex: 0.794734\n",
            "[3150]\ttraining's amex: 0.874155\tvalid_0's amex: 0.794607\n",
            "[3200]\ttraining's amex: 0.875387\tvalid_0's amex: 0.793859\n",
            "[3250]\ttraining's amex: 0.876677\tvalid_0's amex: 0.794318\n",
            "[3300]\ttraining's amex: 0.877704\tvalid_0's amex: 0.794832\n",
            "[3350]\ttraining's amex: 0.878801\tvalid_0's amex: 0.794538\n",
            "[3400]\ttraining's amex: 0.880173\tvalid_0's amex: 0.795006\n",
            "[3450]\ttraining's amex: 0.881209\tvalid_0's amex: 0.794595\n",
            "[3500]\ttraining's amex: 0.882384\tvalid_0's amex: 0.794659\n",
            "[3550]\ttraining's amex: 0.88359\tvalid_0's amex: 0.794475\n",
            "[3600]\ttraining's amex: 0.884817\tvalid_0's amex: 0.794859\n",
            "[3650]\ttraining's amex: 0.886002\tvalid_0's amex: 0.795128\n",
            "[3700]\ttraining's amex: 0.887109\tvalid_0's amex: 0.794696\n",
            "[3750]\ttraining's amex: 0.888507\tvalid_0's amex: 0.795031\n",
            "[3800]\ttraining's amex: 0.889544\tvalid_0's amex: 0.795571\n",
            "[3850]\ttraining's amex: 0.891035\tvalid_0's amex: 0.79551\n",
            "[3900]\ttraining's amex: 0.892174\tvalid_0's amex: 0.795782\n",
            "[3950]\ttraining's amex: 0.893285\tvalid_0's amex: 0.794737\n",
            "[4000]\ttraining's amex: 0.894019\tvalid_0's amex: 0.794794\n",
            "[4050]\ttraining's amex: 0.895485\tvalid_0's amex: 0.794666\n",
            "[4100]\ttraining's amex: 0.89686\tvalid_0's amex: 0.794857\n",
            "[4150]\ttraining's amex: 0.898351\tvalid_0's amex: 0.795346\n",
            "[4200]\ttraining's amex: 0.899461\tvalid_0's amex: 0.795455\n",
            "[4250]\ttraining's amex: 0.900603\tvalid_0's amex: 0.795434\n",
            "[4300]\ttraining's amex: 0.901753\tvalid_0's amex: 0.794852\n",
            "[4350]\ttraining's amex: 0.902751\tvalid_0's amex: 0.795284\n",
            "[4400]\ttraining's amex: 0.904042\tvalid_0's amex: 0.795206\n",
            "[4450]\ttraining's amex: 0.905372\tvalid_0's amex: 0.795182\n",
            "[4500]\ttraining's amex: 0.90696\tvalid_0's amex: 0.795197\n",
            "[4550]\ttraining's amex: 0.907866\tvalid_0's amex: 0.794765\n",
            "[4600]\ttraining's amex: 0.909002\tvalid_0's amex: 0.794637\n",
            "[4650]\ttraining's amex: 0.910257\tvalid_0's amex: 0.794888\n",
            "[4700]\ttraining's amex: 0.911348\tvalid_0's amex: 0.794849\n",
            "[4750]\ttraining's amex: 0.912442\tvalid_0's amex: 0.795636\n",
            "[4800]\ttraining's amex: 0.913464\tvalid_0's amex: 0.795759\n",
            "[4850]\ttraining's amex: 0.914624\tvalid_0's amex: 0.795918\n",
            "[4900]\ttraining's amex: 0.91564\tvalid_0's amex: 0.795476\n",
            "[4950]\ttraining's amex: 0.916926\tvalid_0's amex: 0.795269\n",
            "[5000]\ttraining's amex: 0.917821\tvalid_0's amex: 0.795333\n",
            "[5050]\ttraining's amex: 0.919112\tvalid_0's amex: 0.794999\n",
            "[5100]\ttraining's amex: 0.920026\tvalid_0's amex: 0.794721\n",
            "[5150]\ttraining's amex: 0.920995\tvalid_0's amex: 0.794553\n",
            "[5200]\ttraining's amex: 0.922042\tvalid_0's amex: 0.794687\n",
            "[5250]\ttraining's amex: 0.923142\tvalid_0's amex: 0.79473\n",
            "[5300]\ttraining's amex: 0.924439\tvalid_0's amex: 0.794719\n",
            "[5350]\ttraining's amex: 0.925282\tvalid_0's amex: 0.794785\n",
            "[5400]\ttraining's amex: 0.92618\tvalid_0's amex: 0.795411\n",
            "[5450]\ttraining's amex: 0.927343\tvalid_0's amex: 0.795397\n",
            "[5500]\ttraining's amex: 0.928558\tvalid_0's amex: 0.795283\n",
            "[5550]\ttraining's amex: 0.92939\tvalid_0's amex: 0.795835\n",
            "[5600]\ttraining's amex: 0.930532\tvalid_0's amex: 0.795206\n",
            "[5650]\ttraining's amex: 0.931309\tvalid_0's amex: 0.795373\n",
            "[5700]\ttraining's amex: 0.932187\tvalid_0's amex: 0.795844\n",
            "[5750]\ttraining's amex: 0.932922\tvalid_0's amex: 0.795821\n",
            "[5800]\ttraining's amex: 0.933841\tvalid_0's amex: 0.795586\n",
            "[5850]\ttraining's amex: 0.934759\tvalid_0's amex: 0.795527\n",
            "[5900]\ttraining's amex: 0.935735\tvalid_0's amex: 0.795688\n",
            "[5950]\ttraining's amex: 0.936483\tvalid_0's amex: 0.795772\n",
            "[6000]\ttraining's amex: 0.937336\tvalid_0's amex: 0.795814\n",
            "[6050]\ttraining's amex: 0.938189\tvalid_0's amex: 0.79573\n",
            "[6100]\ttraining's amex: 0.938956\tvalid_0's amex: 0.795996\n",
            "[6150]\ttraining's amex: 0.939718\tvalid_0's amex: 0.796015\n",
            "[6200]\ttraining's amex: 0.940326\tvalid_0's amex: 0.795718\n",
            "[6250]\ttraining's amex: 0.94122\tvalid_0's amex: 0.795818\n",
            "[6300]\ttraining's amex: 0.942029\tvalid_0's amex: 0.795511\n",
            "[6350]\ttraining's amex: 0.943068\tvalid_0's amex: 0.795599\n",
            "[6400]\ttraining's amex: 0.943951\tvalid_0's amex: 0.795651\n",
            "[6450]\ttraining's amex: 0.944733\tvalid_0's amex: 0.795451\n",
            "[6500]\ttraining's amex: 0.945488\tvalid_0's amex: 0.795528\n",
            "[6550]\ttraining's amex: 0.946216\tvalid_0's amex: 0.79522\n",
            "[6600]\ttraining's amex: 0.947125\tvalid_0's amex: 0.795277\n",
            "[6650]\ttraining's amex: 0.948013\tvalid_0's amex: 0.795491\n",
            "[6700]\ttraining's amex: 0.948551\tvalid_0's amex: 0.79553\n",
            "[6750]\ttraining's amex: 0.949138\tvalid_0's amex: 0.79532\n",
            "[6800]\ttraining's amex: 0.949966\tvalid_0's amex: 0.795296\n",
            "[6850]\ttraining's amex: 0.950592\tvalid_0's amex: 0.795569\n",
            "[6900]\ttraining's amex: 0.951256\tvalid_0's amex: 0.795592\n",
            "[6950]\ttraining's amex: 0.952273\tvalid_0's amex: 0.795763\n",
            "[7000]\ttraining's amex: 0.953082\tvalid_0's amex: 0.795801\n",
            "[7050]\ttraining's amex: 0.953993\tvalid_0's amex: 0.795759\n",
            "[7100]\ttraining's amex: 0.954623\tvalid_0's amex: 0.796009\n",
            "[7150]\ttraining's amex: 0.955332\tvalid_0's amex: 0.79574\n",
            "[7200]\ttraining's amex: 0.956027\tvalid_0's amex: 0.795719\n",
            "[7250]\ttraining's amex: 0.95663\tvalid_0's amex: 0.795576\n",
            "[7300]\ttraining's amex: 0.957377\tvalid_0's amex: 0.795906\n",
            "[7350]\ttraining's amex: 0.957965\tvalid_0's amex: 0.795898\n",
            "[7400]\ttraining's amex: 0.958537\tvalid_0's amex: 0.795789\n",
            "[7450]\ttraining's amex: 0.959413\tvalid_0's amex: 0.796055\n",
            "[7500]\ttraining's amex: 0.960105\tvalid_0's amex: 0.796144\n",
            "[7550]\ttraining's amex: 0.960778\tvalid_0's amex: 0.796044\n",
            "[7600]\ttraining's amex: 0.961468\tvalid_0's amex: 0.795809\n",
            "[7650]\ttraining's amex: 0.962159\tvalid_0's amex: 0.795643\n",
            "[7700]\ttraining's amex: 0.962821\tvalid_0's amex: 0.795961\n",
            "[7750]\ttraining's amex: 0.963511\tvalid_0's amex: 0.795526\n",
            "[7800]\ttraining's amex: 0.96447\tvalid_0's amex: 0.796202\n",
            "[7850]\ttraining's amex: 0.965224\tvalid_0's amex: 0.795748\n",
            "[7900]\ttraining's amex: 0.965878\tvalid_0's amex: 0.79559\n",
            "[7950]\ttraining's amex: 0.966508\tvalid_0's amex: 0.796503\n",
            "[8000]\ttraining's amex: 0.966991\tvalid_0's amex: 0.795482\n",
            "[8050]\ttraining's amex: 0.96759\tvalid_0's amex: 0.795734\n",
            "[8100]\ttraining's amex: 0.968142\tvalid_0's amex: 0.795695\n",
            "[8150]\ttraining's amex: 0.968811\tvalid_0's amex: 0.795911\n",
            "[8200]\ttraining's amex: 0.969363\tvalid_0's amex: 0.795793\n",
            "[8250]\ttraining's amex: 0.970161\tvalid_0's amex: 0.795719\n",
            "[8300]\ttraining's amex: 0.970847\tvalid_0's amex: 0.795585\n",
            "[8350]\ttraining's amex: 0.971367\tvalid_0's amex: 0.795502\n",
            "[8400]\ttraining's amex: 0.971959\tvalid_0's amex: 0.795842\n",
            "[8450]\ttraining's amex: 0.972414\tvalid_0's amex: 0.795461\n",
            "[8500]\ttraining's amex: 0.972799\tvalid_0's amex: 0.795752\n",
            "[8550]\ttraining's amex: 0.973329\tvalid_0's amex: 0.795563\n",
            "[8600]\ttraining's amex: 0.974026\tvalid_0's amex: 0.795458\n",
            "[8650]\ttraining's amex: 0.974332\tvalid_0's amex: 0.795599\n",
            "[8700]\ttraining's amex: 0.974865\tvalid_0's amex: 0.795448\n",
            "[8750]\ttraining's amex: 0.975366\tvalid_0's amex: 0.795796\n",
            "[8800]\ttraining's amex: 0.975807\tvalid_0's amex: 0.795673\n",
            "[8850]\ttraining's amex: 0.976171\tvalid_0's amex: 0.795695\n",
            "[8900]\ttraining's amex: 0.976802\tvalid_0's amex: 0.795656\n",
            "[8950]\ttraining's amex: 0.977217\tvalid_0's amex: 0.795696\n",
            "[9000]\ttraining's amex: 0.977764\tvalid_0's amex: 0.796058\n",
            "[9050]\ttraining's amex: 0.978304\tvalid_0's amex: 0.795918\n",
            "[9100]\ttraining's amex: 0.978816\tvalid_0's amex: 0.796081\n",
            "[9150]\ttraining's amex: 0.979184\tvalid_0's amex: 0.796459\n",
            "[9200]\ttraining's amex: 0.979676\tvalid_0's amex: 0.796294\n",
            "[9250]\ttraining's amex: 0.980005\tvalid_0's amex: 0.796089\n",
            "[9300]\ttraining's amex: 0.980596\tvalid_0's amex: 0.796068\n",
            "[9350]\ttraining's amex: 0.981026\tvalid_0's amex: 0.796171\n",
            "[9400]\ttraining's amex: 0.981391\tvalid_0's amex: 0.796095\n",
            "[9450]\ttraining's amex: 0.98172\tvalid_0's amex: 0.796073\n",
            "[9500]\ttraining's amex: 0.982188\tvalid_0's amex: 0.796511\n",
            "[9550]\ttraining's amex: 0.982581\tvalid_0's amex: 0.796508\n",
            "[9600]\ttraining's amex: 0.983071\tvalid_0's amex: 0.796571\n",
            "[9650]\ttraining's amex: 0.983413\tvalid_0's amex: 0.796636\n",
            "[9700]\ttraining's amex: 0.983877\tvalid_0's amex: 0.796557\n",
            "[9750]\ttraining's amex: 0.984277\tvalid_0's amex: 0.796283\n",
            "[9800]\ttraining's amex: 0.984679\tvalid_0's amex: 0.79636\n",
            "[9850]\ttraining's amex: 0.985149\tvalid_0's amex: 0.796313\n",
            "[9900]\ttraining's amex: 0.985451\tvalid_0's amex: 0.795808\n",
            "[9950]\ttraining's amex: 0.985811\tvalid_0's amex: 0.7961\n",
            "[10000]\ttraining's amex: 0.986177\tvalid_0's amex: 0.795791\n",
            "[10050]\ttraining's amex: 0.986616\tvalid_0's amex: 0.796039\n",
            "[10100]\ttraining's amex: 0.986938\tvalid_0's amex: 0.79566\n",
            "[10150]\ttraining's amex: 0.987382\tvalid_0's amex: 0.795516\n",
            "[10200]\ttraining's amex: 0.987833\tvalid_0's amex: 0.795615\n",
            "[10250]\ttraining's amex: 0.988108\tvalid_0's amex: 0.795909\n",
            "[10300]\ttraining's amex: 0.988462\tvalid_0's amex: 0.79553\n",
            "[10350]\ttraining's amex: 0.988766\tvalid_0's amex: 0.795654\n",
            "[10400]\ttraining's amex: 0.989055\tvalid_0's amex: 0.795619\n",
            "[10450]\ttraining's amex: 0.98937\tvalid_0's amex: 0.795615\n",
            "[10500]\ttraining's amex: 0.989814\tvalid_0's amex: 0.795233\n",
            "[10550]\ttraining's amex: 0.99005\tvalid_0's amex: 0.795289\n",
            "[10600]\ttraining's amex: 0.990334\tvalid_0's amex: 0.795627\n",
            "[10650]\ttraining's amex: 0.990671\tvalid_0's amex: 0.79502\n",
            "[10700]\ttraining's amex: 0.990908\tvalid_0's amex: 0.794871\n",
            "[10750]\ttraining's amex: 0.991192\tvalid_0's amex: 0.79504\n",
            "[10800]\ttraining's amex: 0.991446\tvalid_0's amex: 0.795043\n",
            "[10850]\ttraining's amex: 0.991778\tvalid_0's amex: 0.795233\n",
            "[10900]\ttraining's amex: 0.992052\tvalid_0's amex: 0.795248\n",
            "[10950]\ttraining's amex: 0.992264\tvalid_0's amex: 0.795033\n",
            "[11000]\ttraining's amex: 0.992569\tvalid_0's amex: 0.794681\n",
            "[11050]\ttraining's amex: 0.992833\tvalid_0's amex: 0.794715\n",
            "[11100]\ttraining's amex: 0.993145\tvalid_0's amex: 0.794231\n",
            "[11150]\ttraining's amex: 0.993302\tvalid_0's amex: 0.794571\n",
            "[11200]\ttraining's amex: 0.993574\tvalid_0's amex: 0.794275\n",
            "[11250]\ttraining's amex: 0.993873\tvalid_0's amex: 0.794362\n",
            "[11300]\ttraining's amex: 0.993999\tvalid_0's amex: 0.794305\n",
            "[11350]\ttraining's amex: 0.994297\tvalid_0's amex: 0.79417\n",
            "[11400]\ttraining's amex: 0.994582\tvalid_0's amex: 0.794335\n",
            "[11450]\ttraining's amex: 0.994773\tvalid_0's amex: 0.794394\n",
            "[11500]\ttraining's amex: 0.994891\tvalid_0's amex: 0.79431\n",
            "[11550]\ttraining's amex: 0.995074\tvalid_0's amex: 0.794018\n",
            "[11600]\ttraining's amex: 0.995284\tvalid_0's amex: 0.793851\n",
            "[11650]\ttraining's amex: 0.995502\tvalid_0's amex: 0.793728\n",
            "[11700]\ttraining's amex: 0.995676\tvalid_0's amex: 0.79427\n",
            "[11750]\ttraining's amex: 0.995848\tvalid_0's amex: 0.793977\n",
            "[11800]\ttraining's amex: 0.996032\tvalid_0's amex: 0.793972\n",
            "[11850]\ttraining's amex: 0.996235\tvalid_0's amex: 0.794302\n",
            "[11900]\ttraining's amex: 0.99642\tvalid_0's amex: 0.793967\n",
            "[11950]\ttraining's amex: 0.996566\tvalid_0's amex: 0.793906\n",
            "[12000]\ttraining's amex: 0.996755\tvalid_0's amex: 0.793944\n",
            "[12050]\ttraining's amex: 0.996867\tvalid_0's amex: 0.794064\n",
            "[12100]\ttraining's amex: 0.996992\tvalid_0's amex: 0.793978\n",
            "[12150]\ttraining's amex: 0.997125\tvalid_0's amex: 0.793995\n",
            "[12200]\ttraining's amex: 0.997267\tvalid_0's amex: 0.794221\n",
            "[12250]\ttraining's amex: 0.99741\tvalid_0's amex: 0.794182\n",
            "[12300]\ttraining's amex: 0.997633\tvalid_0's amex: 0.794275\n",
            "[12350]\ttraining's amex: 0.99777\tvalid_0's amex: 0.794095\n",
            "[12400]\ttraining's amex: 0.997868\tvalid_0's amex: 0.794244\n",
            "[12450]\ttraining's amex: 0.997949\tvalid_0's amex: 0.793843\n",
            "[12500]\ttraining's amex: 0.998055\tvalid_0's amex: 0.793839\n",
            "[12550]\ttraining's amex: 0.99815\tvalid_0's amex: 0.794193\n",
            "[12600]\ttraining's amex: 0.998224\tvalid_0's amex: 0.794403\n",
            "[12650]\ttraining's amex: 0.998281\tvalid_0's amex: 0.79446\n",
            "[12700]\ttraining's amex: 0.998398\tvalid_0's amex: 0.794544\n",
            "[12750]\ttraining's amex: 0.998473\tvalid_0's amex: 0.794671\n",
            "[12800]\ttraining's amex: 0.998581\tvalid_0's amex: 0.794734\n",
            "[12850]\ttraining's amex: 0.998655\tvalid_0's amex: 0.794405\n",
            "[12900]\ttraining's amex: 0.998735\tvalid_0's amex: 0.794195\n",
            "[12950]\ttraining's amex: 0.99879\tvalid_0's amex: 0.794595\n",
            "[13000]\ttraining's amex: 0.998842\tvalid_0's amex: 0.794598\n",
            "[13050]\ttraining's amex: 0.998911\tvalid_0's amex: 0.794556\n",
            "[13100]\ttraining's amex: 0.998965\tvalid_0's amex: 0.794616\n",
            "[13150]\ttraining's amex: 0.998996\tvalid_0's amex: 0.794841\n",
            "[13200]\ttraining's amex: 0.999054\tvalid_0's amex: 0.794803\n",
            "[13250]\ttraining's amex: 0.999104\tvalid_0's amex: 0.795088\n",
            "[13300]\ttraining's amex: 0.999145\tvalid_0's amex: 0.794841\n",
            "[13350]\ttraining's amex: 0.999163\tvalid_0's amex: 0.794691\n",
            "[13400]\ttraining's amex: 0.99918\tvalid_0's amex: 0.794379\n",
            "[13450]\ttraining's amex: 0.999224\tvalid_0's amex: 0.794799\n",
            "[13500]\ttraining's amex: 0.999279\tvalid_0's amex: 0.79493\n",
            "[13550]\ttraining's amex: 0.999323\tvalid_0's amex: 0.794952\n",
            "[13600]\ttraining's amex: 0.999343\tvalid_0's amex: 0.794845\n",
            "[13650]\ttraining's amex: 0.999378\tvalid_0's amex: 0.794774\n",
            "[13700]\ttraining's amex: 0.99941\tvalid_0's amex: 0.79448\n",
            "[13750]\ttraining's amex: 0.999465\tvalid_0's amex: 0.794793\n",
            "[13800]\ttraining's amex: 0.999492\tvalid_0's amex: 0.79478\n",
            "[13850]\ttraining's amex: 0.999513\tvalid_0's amex: 0.794533\n",
            "[13900]\ttraining's amex: 0.999517\tvalid_0's amex: 0.794489\n",
            "[13950]\ttraining's amex: 0.99955\tvalid_0's amex: 0.794547\n",
            "[14000]\ttraining's amex: 0.999598\tvalid_0's amex: 0.794802\n",
            "[14050]\ttraining's amex: 0.999613\tvalid_0's amex: 0.794721\n",
            "[14100]\ttraining's amex: 0.999623\tvalid_0's amex: 0.794891\n",
            "[14150]\ttraining's amex: 0.999665\tvalid_0's amex: 0.795125\n",
            "[14200]\ttraining's amex: 0.99968\tvalid_0's amex: 0.794824\n",
            "[14250]\ttraining's amex: 0.99969\tvalid_0's amex: 0.79522\n",
            "[14300]\ttraining's amex: 0.999693\tvalid_0's amex: 0.794843\n",
            "[14350]\ttraining's amex: 0.999724\tvalid_0's amex: 0.794887\n",
            "[14400]\ttraining's amex: 0.999729\tvalid_0's amex: 0.794846\n",
            "[14450]\ttraining's amex: 0.999739\tvalid_0's amex: 0.794972\n",
            "[14500]\ttraining's amex: 0.999758\tvalid_0's amex: 0.79456\n",
            "[14550]\ttraining's amex: 0.999755\tvalid_0's amex: 0.794689\n",
            "[14600]\ttraining's amex: 0.999785\tvalid_0's amex: 0.794792\n",
            "[14650]\ttraining's amex: 0.999789\tvalid_0's amex: 0.794897\n",
            "[14700]\ttraining's amex: 0.999787\tvalid_0's amex: 0.794993\n",
            "[14750]\ttraining's amex: 0.999801\tvalid_0's amex: 0.794954\n",
            "[14800]\ttraining's amex: 0.999814\tvalid_0's amex: 0.795062\n",
            "[14850]\ttraining's amex: 0.999811\tvalid_0's amex: 0.794934\n",
            "[14900]\ttraining's amex: 0.999818\tvalid_0's amex: 0.795263\n",
            "[14950]\ttraining's amex: 0.999831\tvalid_0's amex: 0.794739\n",
            "[15000]\ttraining's amex: 0.999834\tvalid_0's amex: 0.79494\n",
            "[15050]\ttraining's amex: 0.99984\tvalid_0's amex: 0.79511\n",
            "[15100]\ttraining's amex: 0.999842\tvalid_0's amex: 0.795257\n",
            "[15150]\ttraining's amex: 0.99986\tvalid_0's amex: 0.795261\n",
            "[15200]\ttraining's amex: 0.999861\tvalid_0's amex: 0.794882\n",
            "[15250]\ttraining's amex: 0.999863\tvalid_0's amex: 0.795107\n",
            "[15300]\ttraining's amex: 0.99987\tvalid_0's amex: 0.79488\n",
            "[15350]\ttraining's amex: 0.999877\tvalid_0's amex: 0.795155\n",
            "[15400]\ttraining's amex: 0.999883\tvalid_0's amex: 0.795117\n",
            "[15450]\ttraining's amex: 0.999901\tvalid_0's amex: 0.79526\n",
            "[15500]\ttraining's amex: 0.999892\tvalid_0's amex: 0.795223\n",
            "[15550]\ttraining's amex: 0.999893\tvalid_0's amex: 0.795281\n",
            "[15600]\ttraining's amex: 0.999899\tvalid_0's amex: 0.795051\n",
            "[15650]\ttraining's amex: 0.999905\tvalid_0's amex: 0.795071\n",
            "[15700]\ttraining's amex: 0.999917\tvalid_0's amex: 0.795028\n",
            "[15750]\ttraining's amex: 0.999929\tvalid_0's amex: 0.795336\n",
            "[15800]\ttraining's amex: 0.99993\tvalid_0's amex: 0.795361\n",
            "[15850]\ttraining's amex: 0.999931\tvalid_0's amex: 0.795065\n",
            "[15900]\ttraining's amex: 0.999937\tvalid_0's amex: 0.79519\n",
            "[15950]\ttraining's amex: 0.999937\tvalid_0's amex: 0.795201\n",
            "[16000]\ttraining's amex: 0.999939\tvalid_0's amex: 0.795076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AutoTUNE with OPTUNA"
      ],
      "metadata": {
        "id": "EoSatpVvOSOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n",
        "import lightgbm as lgb\n",
        "import optuna.integration.lightgbm as lgb\n",
        "import optuna\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_qNmRz2BQ1A",
        "outputId": "a3b3cb4b-f4d8-4a9d-ccff-f206a7bd5800"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.2.2 alembic-1.8.1 autopage-0.5.1 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.2 colorlog-6.7.0 optuna-3.0.0 pbr-5.10.0 pyperclip-1.8.2 stevedore-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    # define search intervals for the parameters\n",
        "    param={\n",
        "          'objective':'binary',\n",
        "          # 'metric':'binary_logloss',\n",
        "          # 'verbosity':-1,\n",
        "          # 'boosting_type':'dart',\n",
        "          \"bagging_fraction\": trial.suggest_loguniform(\"bagging_fraction\", 0.4, 0.8),\n",
        "          # \"max_depth\": trial.suggest_int(\"max_depth\", 25, 40,4),\n",
        "          \"num_leaves\": trial.suggest_int(\"num_leaves\", 60, 120,10),\n",
        "          \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.15),\n",
        "          # \"bagging_freq\": trial.suggest_categorical(\"bagging_freq\", [10]),\n",
        "          \"feature_fraction\": trial.suggest_loguniform(\"feature_fraction\", 0.05, 0.4), \n",
        "          # 'feature_fraction_bynode':trial.suggest_loguniform(\"feature_fraction_bynode\", 0.3, 0.90), \n",
        "          \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 60, 120,10),\n",
        "          \"metric\": \"None\",\n",
        "          # \"first_metric_only\": True,\n",
        "          \"seed\": 50\n",
        "            }\n",
        "    # run model     \n",
        "\n",
        "    lgb_train = lgb.Dataset(x_train, label=y_train,\n",
        "                         free_raw_data=False)\n",
        "    lgb_eval = lgb.Dataset(x_val, label=y_val, reference=lgb_train,\n",
        "                        free_raw_data=False)\n",
        "    \n",
        "    gbm = lgb.train(param,\n",
        "                    num_boost_round=10000,\n",
        "                    train_set=lgb_train,\n",
        "                    valid_sets=[lgb_eval],\n",
        "                    feval=amex,\n",
        "                    early_stopping_rounds=4500,\n",
        "                    verbose_eval=200\n",
        "                    )\n",
        "\n",
        "    cv_score=gbm.best_score['valid_0']['amex']\n",
        "    return cv_score\n",
        "\n",
        "# Suppress information only outputs\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "study_name = \"example-study-long\"  # Unique identifier of the study.\n",
        "storage_name = \"sqlite:///{}.db\".format(study_name)\n",
        "study = optuna.create_study(direction='maximize',study_name=study_name, storage=storage_name,load_if_exists=True)\n",
        "study.optimize(objective,timeout=24000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WatsN3uNBRCn",
        "outputId": "91c0db11-5c82-4a83-cb65-a822e7eaa2f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 4500 rounds.\n",
            "[200]\tvalid_0's amex: 0.781134\n",
            "[400]\tvalid_0's amex: 0.78965\n",
            "[600]\tvalid_0's amex: 0.791275\n",
            "[800]\tvalid_0's amex: 0.79288\n",
            "[1000]\tvalid_0's amex: 0.793546\n",
            "[1200]\tvalid_0's amex: 0.794084\n",
            "[1400]\tvalid_0's amex: 0.794102\n",
            "[1600]\tvalid_0's amex: 0.794537\n",
            "[1800]\tvalid_0's amex: 0.794578\n",
            "[2000]\tvalid_0's amex: 0.79381\n",
            "[2200]\tvalid_0's amex: 0.794038\n",
            "[2400]\tvalid_0's amex: 0.793757\n",
            "[2600]\tvalid_0's amex: 0.794025\n",
            "[2800]\tvalid_0's amex: 0.793659\n",
            "[3000]\tvalid_0's amex: 0.794051\n",
            "[3200]\tvalid_0's amex: 0.793764\n",
            "[3400]\tvalid_0's amex: 0.794056\n",
            "[3600]\tvalid_0's amex: 0.7944\n",
            "[3800]\tvalid_0's amex: 0.794269\n",
            "[4000]\tvalid_0's amex: 0.794086\n",
            "[4200]\tvalid_0's amex: 0.793708\n",
            "[4400]\tvalid_0's amex: 0.794052\n",
            "[4600]\tvalid_0's amex: 0.794443\n",
            "[4800]\tvalid_0's amex: 0.794152\n",
            "[5000]\tvalid_0's amex: 0.794453\n",
            "[5200]\tvalid_0's amex: 0.794516\n",
            "[5400]\tvalid_0's amex: 0.794207\n",
            "[5600]\tvalid_0's amex: 0.794571\n",
            "[5800]\tvalid_0's amex: 0.794054\n",
            "[6000]\tvalid_0's amex: 0.793878\n",
            "Early stopping, best iteration is:\n",
            "[1633]\tvalid_0's amex: 0.795191\n",
            "Training until validation scores don't improve for 4500 rounds.\n",
            "[200]\tvalid_0's amex: 0.790668\n",
            "[400]\tvalid_0's amex: 0.789836\n",
            "[600]\tvalid_0's amex: 0.78891\n",
            "[800]\tvalid_0's amex: 0.788868\n",
            "[1000]\tvalid_0's amex: 0.789459\n",
            "[1200]\tvalid_0's amex: 0.790236\n",
            "[1400]\tvalid_0's amex: 0.789322\n",
            "[1600]\tvalid_0's amex: 0.789083\n",
            "[1800]\tvalid_0's amex: 0.788992\n",
            "[2000]\tvalid_0's amex: 0.788603\n",
            "[2200]\tvalid_0's amex: 0.789755\n",
            "[2400]\tvalid_0's amex: 0.789024\n",
            "[2600]\tvalid_0's amex: 0.790323\n",
            "[2800]\tvalid_0's amex: 0.789746\n",
            "[3000]\tvalid_0's amex: 0.790539\n",
            "[3200]\tvalid_0's amex: 0.79031\n",
            "[3400]\tvalid_0's amex: 0.79047\n",
            "[3600]\tvalid_0's amex: 0.791187\n",
            "[3800]\tvalid_0's amex: 0.791133\n",
            "[4000]\tvalid_0's amex: 0.790819\n",
            "[4200]\tvalid_0's amex: 0.79104\n",
            "[4400]\tvalid_0's amex: 0.790859\n",
            "[4600]\tvalid_0's amex: 0.790892\n",
            "[4800]\tvalid_0's amex: 0.791261\n",
            "Early stopping, best iteration is:\n",
            "[316]\tvalid_0's amex: 0.791669\n",
            "Training until validation scores don't improve for 4500 rounds.\n",
            "[200]\tvalid_0's amex: 0.790467\n",
            "[400]\tvalid_0's amex: 0.791729\n",
            "[600]\tvalid_0's amex: 0.791582\n",
            "[800]\tvalid_0's amex: 0.792839\n",
            "[1000]\tvalid_0's amex: 0.793697\n",
            "[1200]\tvalid_0's amex: 0.793932\n",
            "[1400]\tvalid_0's amex: 0.794333\n",
            "[1600]\tvalid_0's amex: 0.793305\n",
            "[1800]\tvalid_0's amex: 0.793287\n",
            "[2000]\tvalid_0's amex: 0.793064\n",
            "[2200]\tvalid_0's amex: 0.793757\n",
            "[2400]\tvalid_0's amex: 0.793596\n",
            "[2600]\tvalid_0's amex: 0.793735\n",
            "[2800]\tvalid_0's amex: 0.793814\n",
            "[3000]\tvalid_0's amex: 0.794113\n",
            "[3200]\tvalid_0's amex: 0.793532\n",
            "[3400]\tvalid_0's amex: 0.793279\n",
            "[3600]\tvalid_0's amex: 0.793647\n",
            "[3800]\tvalid_0's amex: 0.793618\n",
            "[4000]\tvalid_0's amex: 0.793331\n",
            "[4200]\tvalid_0's amex: 0.793243\n",
            "[4400]\tvalid_0's amex: 0.793856\n",
            "[4600]\tvalid_0's amex: 0.793796\n",
            "[4800]\tvalid_0's amex: 0.793681\n",
            "[5000]\tvalid_0's amex: 0.793115\n",
            "[5200]\tvalid_0's amex: 0.793242\n",
            "[5400]\tvalid_0's amex: 0.793619\n",
            "[5600]\tvalid_0's amex: 0.793386\n",
            "Early stopping, best iteration is:\n",
            "[1162]\tvalid_0's amex: 0.795228\n",
            "Training until validation scores don't improve for 4500 rounds.\n",
            "[200]\tvalid_0's amex: 0.791676\n",
            "[400]\tvalid_0's amex: 0.792188\n",
            "[600]\tvalid_0's amex: 0.791438\n",
            "[800]\tvalid_0's amex: 0.790955\n",
            "[1000]\tvalid_0's amex: 0.791386\n",
            "[1200]\tvalid_0's amex: 0.790489\n",
            "[1400]\tvalid_0's amex: 0.790826\n",
            "[1600]\tvalid_0's amex: 0.791076\n",
            "[1800]\tvalid_0's amex: 0.790716\n",
            "[2000]\tvalid_0's amex: 0.790176\n",
            "[2200]\tvalid_0's amex: 0.792049\n",
            "[2400]\tvalid_0's amex: 0.791817\n",
            "[2600]\tvalid_0's amex: 0.792232\n",
            "[2800]\tvalid_0's amex: 0.792327\n",
            "[3000]\tvalid_0's amex: 0.792895\n",
            "[3200]\tvalid_0's amex: 0.792791\n",
            "[3400]\tvalid_0's amex: 0.792875\n",
            "[3600]\tvalid_0's amex: 0.792824\n",
            "[3800]\tvalid_0's amex: 0.792774\n",
            "[4000]\tvalid_0's amex: 0.792352\n",
            "[4200]\tvalid_0's amex: 0.792407\n",
            "[4400]\tvalid_0's amex: 0.79254\n",
            "[4600]\tvalid_0's amex: 0.792384\n",
            "[4800]\tvalid_0's amex: 0.792671\n",
            "[5000]\tvalid_0's amex: 0.793415\n",
            "[5200]\tvalid_0's amex: 0.793918\n",
            "[5400]\tvalid_0's amex: 0.793639\n",
            "[5600]\tvalid_0's amex: 0.792901\n",
            "[5800]\tvalid_0's amex: 0.792837\n",
            "[6000]\tvalid_0's amex: 0.792929\n",
            "[6200]\tvalid_0's amex: 0.793219\n",
            "[6400]\tvalid_0's amex: 0.792744\n",
            "[6600]\tvalid_0's amex: 0.793009\n",
            "[6800]\tvalid_0's amex: 0.793058\n",
            "[7000]\tvalid_0's amex: 0.792842\n",
            "[7200]\tvalid_0's amex: 0.793051\n",
            "[7400]\tvalid_0's amex: 0.792223\n",
            "[7600]\tvalid_0's amex: 0.792754\n",
            "[7800]\tvalid_0's amex: 0.793154\n",
            "[8000]\tvalid_0's amex: 0.793434\n",
            "[8200]\tvalid_0's amex: 0.793067\n",
            "[8400]\tvalid_0's amex: 0.793362\n",
            "[8600]\tvalid_0's amex: 0.793656\n",
            "[8800]\tvalid_0's amex: 0.793891\n",
            "[9000]\tvalid_0's amex: 0.794179\n",
            "[9200]\tvalid_0's amex: 0.793926\n",
            "[9400]\tvalid_0's amex: 0.793425\n",
            "[9600]\tvalid_0's amex: 0.793566\n",
            "[9800]\tvalid_0's amex: 0.794608\n",
            "[10000]\tvalid_0's amex: 0.794361\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[9879]\tvalid_0's amex: 0.794887\n",
            "Training until validation scores don't improve for 4500 rounds.\n",
            "[200]\tvalid_0's amex: 0.790826\n",
            "[400]\tvalid_0's amex: 0.789414\n",
            "[600]\tvalid_0's amex: 0.789729\n",
            "[800]\tvalid_0's amex: 0.789029\n",
            "[1000]\tvalid_0's amex: 0.789053\n",
            "[1200]\tvalid_0's amex: 0.78847\n",
            "[1400]\tvalid_0's amex: 0.7875\n",
            "[1600]\tvalid_0's amex: 0.788268\n",
            "[1800]\tvalid_0's amex: 0.787486\n",
            "[2000]\tvalid_0's amex: 0.787279\n",
            "[2200]\tvalid_0's amex: 0.788613\n",
            "[2400]\tvalid_0's amex: 0.788587\n",
            "[2600]\tvalid_0's amex: 0.788167\n",
            "[2800]\tvalid_0's amex: 0.787894\n",
            "[3000]\tvalid_0's amex: 0.788281\n",
            "[3200]\tvalid_0's amex: 0.787997\n",
            "[3400]\tvalid_0's amex: 0.789429\n",
            "[3600]\tvalid_0's amex: 0.789647\n",
            "[3800]\tvalid_0's amex: 0.789188\n",
            "[4000]\tvalid_0's amex: 0.789216\n",
            "[4200]\tvalid_0's amex: 0.789259\n",
            "[4400]\tvalid_0's amex: 0.788689\n",
            "[4600]\tvalid_0's amex: 0.789335\n",
            "Early stopping, best iteration is:\n",
            "[257]\tvalid_0's amex: 0.791801\n",
            "Training until validation scores don't improve for 4500 rounds.\n",
            "[200]\tvalid_0's amex: 0.782714\n",
            "[400]\tvalid_0's amex: 0.791188\n",
            "[600]\tvalid_0's amex: 0.792921\n",
            "[800]\tvalid_0's amex: 0.793964\n",
            "[1000]\tvalid_0's amex: 0.793268\n",
            "[1200]\tvalid_0's amex: 0.793863\n",
            "[1400]\tvalid_0's amex: 0.793223\n",
            "[1600]\tvalid_0's amex: 0.794327\n",
            "[1800]\tvalid_0's amex: 0.792979\n",
            "[2000]\tvalid_0's amex: 0.792409\n",
            "[2200]\tvalid_0's amex: 0.793299\n",
            "[2400]\tvalid_0's amex: 0.793817\n",
            "[2600]\tvalid_0's amex: 0.79326\n",
            "[2800]\tvalid_0's amex: 0.793721\n",
            "[3000]\tvalid_0's amex: 0.794516\n",
            "[3200]\tvalid_0's amex: 0.794637\n",
            "[3400]\tvalid_0's amex: 0.794925\n",
            "[3600]\tvalid_0's amex: 0.794673\n",
            "[3800]\tvalid_0's amex: 0.794779\n",
            "[4000]\tvalid_0's amex: 0.79475\n",
            "[4200]\tvalid_0's amex: 0.794821\n",
            "[4400]\tvalid_0's amex: 0.794779\n",
            "[4600]\tvalid_0's amex: 0.794658\n",
            "[4800]\tvalid_0's amex: 0.794665\n",
            "[5000]\tvalid_0's amex: 0.794296\n",
            "[5200]\tvalid_0's amex: 0.794245\n",
            "[5400]\tvalid_0's amex: 0.794436\n",
            "[5600]\tvalid_0's amex: 0.794799\n",
            "[5800]\tvalid_0's amex: 0.79494\n",
            "[6000]\tvalid_0's amex: 0.794578\n",
            "[6200]\tvalid_0's amex: 0.794044\n",
            "[6400]\tvalid_0's amex: 0.794504\n",
            "[6600]\tvalid_0's amex: 0.794839\n",
            "[6800]\tvalid_0's amex: 0.794827\n",
            "[7000]\tvalid_0's amex: 0.794907\n",
            "[7200]\tvalid_0's amex: 0.794727\n",
            "[7400]\tvalid_0's amex: 0.793977\n",
            "[7600]\tvalid_0's amex: 0.794356\n",
            "[7800]\tvalid_0's amex: 0.794422\n",
            "[8000]\tvalid_0's amex: 0.794241\n",
            "[8200]\tvalid_0's amex: 0.794569\n",
            "[8400]\tvalid_0's amex: 0.794484\n",
            "[8600]\tvalid_0's amex: 0.794536\n",
            "[8800]\tvalid_0's amex: 0.794685\n",
            "[9000]\tvalid_0's amex: 0.795047\n",
            "[9200]\tvalid_0's amex: 0.794824\n",
            "[9400]\tvalid_0's amex: 0.794638\n",
            "[9600]\tvalid_0's amex: 0.794719\n",
            "[9800]\tvalid_0's amex: 0.79496\n",
            "[10000]\tvalid_0's amex: 0.795448\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5711]\tvalid_0's amex: 0.795759\n",
            "Training until validation scores don't improve for 4500 rounds.\n",
            "[200]\tvalid_0's amex: 0.779843\n",
            "[400]\tvalid_0's amex: 0.789403\n",
            "[600]\tvalid_0's amex: 0.792019\n",
            "[800]\tvalid_0's amex: 0.793097\n",
            "[1000]\tvalid_0's amex: 0.793287\n",
            "[1200]\tvalid_0's amex: 0.794597\n",
            "[1400]\tvalid_0's amex: 0.794667\n",
            "[1600]\tvalid_0's amex: 0.794435\n",
            "[1800]\tvalid_0's amex: 0.794699\n",
            "[2000]\tvalid_0's amex: 0.794562\n",
            "[2200]\tvalid_0's amex: 0.794617\n",
            "[2400]\tvalid_0's amex: 0.794396\n",
            "[2600]\tvalid_0's amex: 0.795142\n",
            "[2800]\tvalid_0's amex: 0.794829\n",
            "[3000]\tvalid_0's amex: 0.795154\n",
            "[3200]\tvalid_0's amex: 0.795261\n",
            "[3400]\tvalid_0's amex: 0.795208\n",
            "[3600]\tvalid_0's amex: 0.795064\n",
            "[3800]\tvalid_0's amex: 0.794651\n",
            "[4000]\tvalid_0's amex: 0.794225\n",
            "[4200]\tvalid_0's amex: 0.794654\n",
            "[4400]\tvalid_0's amex: 0.795103\n",
            "[4600]\tvalid_0's amex: 0.795197\n",
            "[4800]\tvalid_0's amex: 0.794949\n",
            "[5000]\tvalid_0's amex: 0.794948\n",
            "[5200]\tvalid_0's amex: 0.794638\n",
            "[5400]\tvalid_0's amex: 0.794481\n",
            "[5600]\tvalid_0's amex: 0.794073\n",
            "[5800]\tvalid_0's amex: 0.79437\n",
            "[6000]\tvalid_0's amex: 0.794541\n",
            "[6200]\tvalid_0's amex: 0.795185\n",
            "[6400]\tvalid_0's amex: 0.795102\n",
            "[6600]\tvalid_0's amex: 0.795169\n",
            "[6800]\tvalid_0's amex: 0.795193\n",
            "[7000]\tvalid_0's amex: 0.794957\n",
            "Early stopping, best iteration is:\n",
            "[2553]\tvalid_0's amex: 0.795703\n",
            "Training until validation scores don't improve for 4500 rounds.\n",
            "[200]\tvalid_0's amex: 0.788576\n",
            "[400]\tvalid_0's amex: 0.789601\n",
            "[600]\tvalid_0's amex: 0.787907\n",
            "[800]\tvalid_0's amex: 0.787487\n",
            "[1000]\tvalid_0's amex: 0.78674\n",
            "[1200]\tvalid_0's amex: 0.788195\n",
            "[1400]\tvalid_0's amex: 0.788289\n",
            "[1600]\tvalid_0's amex: 0.788567\n",
            "[1800]\tvalid_0's amex: 0.787905\n",
            "[2000]\tvalid_0's amex: 0.787756\n",
            "[2200]\tvalid_0's amex: 0.787755\n",
            "[2400]\tvalid_0's amex: 0.788616\n",
            "[2600]\tvalid_0's amex: 0.788\n",
            "[2800]\tvalid_0's amex: 0.787496\n",
            "[3000]\tvalid_0's amex: 0.788905\n",
            "[3200]\tvalid_0's amex: 0.788924\n",
            "[3400]\tvalid_0's amex: 0.788887\n",
            "[3600]\tvalid_0's amex: 0.789516\n",
            "[3800]\tvalid_0's amex: 0.789505\n",
            "[4000]\tvalid_0's amex: 0.788947\n",
            "[4200]\tvalid_0's amex: 0.789665\n",
            "[4400]\tvalid_0's amex: 0.789878\n",
            "[4600]\tvalid_0's amex: 0.789723\n",
            "[4800]\tvalid_0's amex: 0.789557\n",
            "Early stopping, best iteration is:\n",
            "[316]\tvalid_0's amex: 0.790887\n",
            "Training until validation scores don't improve for 4500 rounds.\n",
            "[200]\tvalid_0's amex: 0.785411\n",
            "[400]\tvalid_0's amex: 0.790137\n",
            "[600]\tvalid_0's amex: 0.793188\n",
            "[800]\tvalid_0's amex: 0.792567\n",
            "[1000]\tvalid_0's amex: 0.793465\n",
            "[1200]\tvalid_0's amex: 0.793422\n",
            "[1400]\tvalid_0's amex: 0.793317\n",
            "[1600]\tvalid_0's amex: 0.793259\n",
            "[1800]\tvalid_0's amex: 0.793267\n",
            "[2000]\tvalid_0's amex: 0.792801\n",
            "[2200]\tvalid_0's amex: 0.793472\n",
            "[2400]\tvalid_0's amex: 0.79297\n",
            "[2600]\tvalid_0's amex: 0.792988\n",
            "[2800]\tvalid_0's amex: 0.793062\n",
            "[3000]\tvalid_0's amex: 0.793288\n",
            "[3200]\tvalid_0's amex: 0.793425\n",
            "[3400]\tvalid_0's amex: 0.793493\n",
            "[3600]\tvalid_0's amex: 0.793078\n",
            "[3800]\tvalid_0's amex: 0.793515\n",
            "[4000]\tvalid_0's amex: 0.794439\n",
            "[4200]\tvalid_0's amex: 0.793368\n",
            "[4400]\tvalid_0's amex: 0.794162\n",
            "[4600]\tvalid_0's amex: 0.79447\n",
            "[4800]\tvalid_0's amex: 0.795185\n",
            "[5000]\tvalid_0's amex: 0.79475\n",
            "[5200]\tvalid_0's amex: 0.794577\n",
            "[5400]\tvalid_0's amex: 0.794922\n",
            "[5600]\tvalid_0's amex: 0.794973\n",
            "[5800]\tvalid_0's amex: 0.79533\n",
            "[6000]\tvalid_0's amex: 0.79524\n",
            "[6200]\tvalid_0's amex: 0.794901\n",
            "[6400]\tvalid_0's amex: 0.794679\n",
            "[6600]\tvalid_0's amex: 0.79496\n",
            "[6800]\tvalid_0's amex: 0.794727\n",
            "[7000]\tvalid_0's amex: 0.794448\n",
            "[7200]\tvalid_0's amex: 0.79423\n",
            "[7400]\tvalid_0's amex: 0.794401\n",
            "[7600]\tvalid_0's amex: 0.794152\n",
            "[7800]\tvalid_0's amex: 0.793719\n",
            "[8000]\tvalid_0's amex: 0.793599\n",
            "[8200]\tvalid_0's amex: 0.793543\n",
            "[8400]\tvalid_0's amex: 0.793425\n",
            "[8600]\tvalid_0's amex: 0.794284\n",
            "[8800]\tvalid_0's amex: 0.793603\n",
            "[9000]\tvalid_0's amex: 0.794396\n",
            "[9200]\tvalid_0's amex: 0.794123\n",
            "[9400]\tvalid_0's amex: 0.794033\n",
            "[9600]\tvalid_0's amex: 0.794091\n",
            "[9800]\tvalid_0's amex: 0.794383\n",
            "[10000]\tvalid_0's amex: 0.793904\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5940]\tvalid_0's amex: 0.795979\n",
            "Training until validation scores don't improve for 4500 rounds.\n",
            "[200]\tvalid_0's amex: 0.789988\n",
            "[400]\tvalid_0's amex: 0.79212\n",
            "[600]\tvalid_0's amex: 0.791489\n",
            "[800]\tvalid_0's amex: 0.792432\n",
            "[1000]\tvalid_0's amex: 0.792547\n",
            "[1200]\tvalid_0's amex: 0.79289\n",
            "[1400]\tvalid_0's amex: 0.792634\n",
            "[1600]\tvalid_0's amex: 0.79193\n",
            "[1800]\tvalid_0's amex: 0.7929\n",
            "[2000]\tvalid_0's amex: 0.791994\n",
            "[2200]\tvalid_0's amex: 0.791604\n",
            "[2400]\tvalid_0's amex: 0.792335\n",
            "[2600]\tvalid_0's amex: 0.792359\n",
            "[2800]\tvalid_0's amex: 0.792522\n",
            "[3000]\tvalid_0's amex: 0.79376\n",
            "[3200]\tvalid_0's amex: 0.793229\n",
            "[3400]\tvalid_0's amex: 0.793739\n",
            "[3600]\tvalid_0's amex: 0.793579\n",
            "[3800]\tvalid_0's amex: 0.793252\n",
            "[4000]\tvalid_0's amex: 0.793376\n",
            "[4200]\tvalid_0's amex: 0.793499\n",
            "[4400]\tvalid_0's amex: 0.793976\n",
            "[4600]\tvalid_0's amex: 0.794623\n",
            "[4800]\tvalid_0's amex: 0.793903\n",
            "[5000]\tvalid_0's amex: 0.794061\n",
            "[5200]\tvalid_0's amex: 0.794278\n",
            "[5400]\tvalid_0's amex: 0.79461\n",
            "[5600]\tvalid_0's amex: 0.795062\n",
            "[5800]\tvalid_0's amex: 0.795112\n",
            "[6000]\tvalid_0's amex: 0.794507\n",
            "[6200]\tvalid_0's amex: 0.794379\n",
            "[6400]\tvalid_0's amex: 0.794832\n",
            "[6600]\tvalid_0's amex: 0.794657\n",
            "[6800]\tvalid_0's amex: 0.794535\n",
            "[7000]\tvalid_0's amex: 0.794937\n",
            "[7200]\tvalid_0's amex: 0.795462\n",
            "[7400]\tvalid_0's amex: 0.795256\n",
            "[7600]\tvalid_0's amex: 0.795298\n",
            "[7800]\tvalid_0's amex: 0.79573\n",
            "[8000]\tvalid_0's amex: 0.795912\n",
            "[8200]\tvalid_0's amex: 0.795681\n",
            "[8400]\tvalid_0's amex: 0.795816\n",
            "[8600]\tvalid_0's amex: 0.795327\n",
            "[8800]\tvalid_0's amex: 0.795161\n",
            "[9000]\tvalid_0's amex: 0.795298\n",
            "[9200]\tvalid_0's amex: 0.795544\n",
            "[9400]\tvalid_0's amex: 0.795752\n",
            "[9600]\tvalid_0's amex: 0.795917\n",
            "[9800]\tvalid_0's amex: 0.795489\n",
            "[10000]\tvalid_0's amex: 0.795375\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[9458]\tvalid_0's amex: 0.79636\n",
            "Training until validation scores don't improve for 4500 rounds.\n",
            "[200]\tvalid_0's amex: 0.787517\n",
            "[400]\tvalid_0's amex: 0.784963\n",
            "[600]\tvalid_0's amex: 0.785404\n",
            "[800]\tvalid_0's amex: 0.786215\n",
            "[1000]\tvalid_0's amex: 0.786293\n",
            "[1200]\tvalid_0's amex: 0.786966\n",
            "[1400]\tvalid_0's amex: 0.787413\n",
            "[1600]\tvalid_0's amex: 0.78674\n",
            "[1800]\tvalid_0's amex: 0.786895\n",
            "[2000]\tvalid_0's amex: 0.787432\n",
            "[2200]\tvalid_0's amex: 0.787491\n",
            "[2400]\tvalid_0's amex: 0.78732\n",
            "[2600]\tvalid_0's amex: 0.787644\n",
            "[2800]\tvalid_0's amex: 0.788108\n",
            "[3000]\tvalid_0's amex: 0.788384\n",
            "[3200]\tvalid_0's amex: 0.788262\n",
            "[3400]\tvalid_0's amex: 0.788782\n",
            "[3600]\tvalid_0's amex: 0.78889\n",
            "[3800]\tvalid_0's amex: 0.789368\n",
            "[4000]\tvalid_0's amex: 0.789588\n",
            "[4200]\tvalid_0's amex: 0.789857\n",
            "[4400]\tvalid_0's amex: 0.789835\n",
            "[4600]\tvalid_0's amex: 0.790338\n",
            "[4800]\tvalid_0's amex: 0.790194\n",
            "[5000]\tvalid_0's amex: 0.79069\n",
            "[5200]\tvalid_0's amex: 0.791262\n",
            "[5400]\tvalid_0's amex: 0.790539\n",
            "[5600]\tvalid_0's amex: 0.790629\n",
            "[5800]\tvalid_0's amex: 0.791115\n",
            "[6000]\tvalid_0's amex: 0.791628\n",
            "[6200]\tvalid_0's amex: 0.791211\n",
            "[6400]\tvalid_0's amex: 0.791371\n",
            "[6600]\tvalid_0's amex: 0.791741\n",
            "[6800]\tvalid_0's amex: 0.791336\n",
            "[7000]\tvalid_0's amex: 0.791367\n",
            "[7200]\tvalid_0's amex: 0.791886\n",
            "[7400]\tvalid_0's amex: 0.791547\n",
            "[7600]\tvalid_0's amex: 0.791437\n",
            "[7800]\tvalid_0's amex: 0.791855\n",
            "[8000]\tvalid_0's amex: 0.79148\n",
            "[8200]\tvalid_0's amex: 0.79161\n",
            "[8400]\tvalid_0's amex: 0.791437\n",
            "[8600]\tvalid_0's amex: 0.790598\n",
            "[8800]\tvalid_0's amex: 0.79132\n",
            "[9000]\tvalid_0's amex: 0.791749\n",
            "[9200]\tvalid_0's amex: 0.791858\n",
            "[9400]\tvalid_0's amex: 0.790924\n",
            "[9600]\tvalid_0's amex: 0.791526\n",
            "[9800]\tvalid_0's amex: 0.791513\n",
            "[10000]\tvalid_0's amex: 0.792185\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[9969]\tvalid_0's amex: 0.792368\n",
            "Training until validation scores don't improve for 4500 rounds.\n",
            "[200]\tvalid_0's amex: 0.787384\n",
            "[400]\tvalid_0's amex: 0.791923\n",
            "[600]\tvalid_0's amex: 0.792366\n",
            "[800]\tvalid_0's amex: 0.792456\n",
            "[1000]\tvalid_0's amex: 0.793171\n",
            "[1200]\tvalid_0's amex: 0.792733\n",
            "[1400]\tvalid_0's amex: 0.793044\n",
            "[1600]\tvalid_0's amex: 0.791675\n",
            "[1800]\tvalid_0's amex: 0.792027\n",
            "[2000]\tvalid_0's amex: 0.792322\n",
            "[2200]\tvalid_0's amex: 0.792637\n",
            "[2400]\tvalid_0's amex: 0.791762\n",
            "[2600]\tvalid_0's amex: 0.792127\n",
            "[2800]\tvalid_0's amex: 0.791491\n",
            "[3000]\tvalid_0's amex: 0.791491\n",
            "[3200]\tvalid_0's amex: 0.791541\n",
            "[3400]\tvalid_0's amex: 0.791852\n",
            "[3600]\tvalid_0's amex: 0.791389\n",
            "[3800]\tvalid_0's amex: 0.791183\n",
            "[4000]\tvalid_0's amex: 0.791308\n",
            "[4200]\tvalid_0's amex: 0.791835\n",
            "[4400]\tvalid_0's amex: 0.791758\n",
            "[4600]\tvalid_0's amex: 0.791969\n",
            "[4800]\tvalid_0's amex: 0.791806\n",
            "[5000]\tvalid_0's amex: 0.791608\n",
            "[5200]\tvalid_0's amex: 0.791754\n",
            "[5400]\tvalid_0's amex: 0.792005\n",
            "Early stopping, best iteration is:\n",
            "[1020]\tvalid_0's amex: 0.793597\n",
            "Training until validation scores don't improve for 4500 rounds.\n",
            "[200]\tvalid_0's amex: 0.773199\n",
            "[400]\tvalid_0's amex: 0.782157\n",
            "[600]\tvalid_0's amex: 0.789757\n",
            "[800]\tvalid_0's amex: 0.790821\n",
            "[1000]\tvalid_0's amex: 0.792975\n",
            "[1200]\tvalid_0's amex: 0.792957\n",
            "[1400]\tvalid_0's amex: 0.793368\n",
            "[1600]\tvalid_0's amex: 0.793663\n",
            "[1800]\tvalid_0's amex: 0.794348\n",
            "[2000]\tvalid_0's amex: 0.794202\n",
            "[2200]\tvalid_0's amex: 0.794041\n",
            "[2400]\tvalid_0's amex: 0.794344\n",
            "[2600]\tvalid_0's amex: 0.794011\n",
            "[2800]\tvalid_0's amex: 0.795106\n",
            "[3000]\tvalid_0's amex: 0.79441\n",
            "[3200]\tvalid_0's amex: 0.794349\n",
            "[3400]\tvalid_0's amex: 0.794547\n",
            "[3600]\tvalid_0's amex: 0.794326\n",
            "[3800]\tvalid_0's amex: 0.794743\n",
            "[4000]\tvalid_0's amex: 0.794146\n",
            "[4200]\tvalid_0's amex: 0.794985\n",
            "[4400]\tvalid_0's amex: 0.794633\n",
            "[4600]\tvalid_0's amex: 0.794546\n",
            "[4800]\tvalid_0's amex: 0.794205\n",
            "[5000]\tvalid_0's amex: 0.794792\n",
            "[5200]\tvalid_0's amex: 0.794797\n",
            "[5400]\tvalid_0's amex: 0.794968\n",
            "[5600]\tvalid_0's amex: 0.795128\n",
            "[5800]\tvalid_0's amex: 0.794539\n",
            "[6000]\tvalid_0's amex: 0.794989\n",
            "[6200]\tvalid_0's amex: 0.794677\n",
            "[6400]\tvalid_0's amex: 0.794697\n",
            "[6600]\tvalid_0's amex: 0.795093\n",
            "[6800]\tvalid_0's amex: 0.794826\n",
            "[7000]\tvalid_0's amex: 0.794669\n",
            "[7200]\tvalid_0's amex: 0.794645\n",
            "Early stopping, best iteration is:\n",
            "[2812]\tvalid_0's amex: 0.795317\n",
            "Training until validation scores don't improve for 4500 rounds.\n",
            "[200]\tvalid_0's amex: 0.788747\n",
            "[400]\tvalid_0's amex: 0.791474\n",
            "[600]\tvalid_0's amex: 0.791129\n",
            "[800]\tvalid_0's amex: 0.791593\n",
            "[1000]\tvalid_0's amex: 0.791123\n",
            "[1200]\tvalid_0's amex: 0.790504\n",
            "[1400]\tvalid_0's amex: 0.790558\n",
            "[1600]\tvalid_0's amex: 0.790809\n",
            "[1800]\tvalid_0's amex: 0.791047\n",
            "[2000]\tvalid_0's amex: 0.791027\n",
            "[2200]\tvalid_0's amex: 0.791228\n",
            "[2400]\tvalid_0's amex: 0.791255\n",
            "[2600]\tvalid_0's amex: 0.791481\n",
            "[2800]\tvalid_0's amex: 0.791917\n",
            "[3000]\tvalid_0's amex: 0.79228\n",
            "[3200]\tvalid_0's amex: 0.791775\n",
            "[3400]\tvalid_0's amex: 0.791644\n",
            "[3600]\tvalid_0's amex: 0.79171\n",
            "[3800]\tvalid_0's amex: 0.792084\n",
            "[4000]\tvalid_0's amex: 0.792376\n",
            "[4200]\tvalid_0's amex: 0.79244\n",
            "[4400]\tvalid_0's amex: 0.791792\n",
            "[4600]\tvalid_0's amex: 0.791224\n",
            "[4800]\tvalid_0's amex: 0.792005\n",
            "[5000]\tvalid_0's amex: 0.791992\n",
            "[5200]\tvalid_0's amex: 0.791676\n",
            "[5400]\tvalid_0's amex: 0.792227\n",
            "[5600]\tvalid_0's amex: 0.792188\n",
            "[5800]\tvalid_0's amex: 0.792904\n",
            "[6000]\tvalid_0's amex: 0.792494\n",
            "[6200]\tvalid_0's amex: 0.792766\n",
            "[6400]\tvalid_0's amex: 0.792641\n",
            "[6600]\tvalid_0's amex: 0.792705\n",
            "[6800]\tvalid_0's amex: 0.792988\n",
            "[7000]\tvalid_0's amex: 0.793169\n",
            "[7200]\tvalid_0's amex: 0.793074\n",
            "[7400]\tvalid_0's amex: 0.79354\n",
            "[7600]\tvalid_0's amex: 0.793354\n",
            "[7800]\tvalid_0's amex: 0.792943\n",
            "[8000]\tvalid_0's amex: 0.793136\n",
            "[8200]\tvalid_0's amex: 0.793306\n",
            "[8400]\tvalid_0's amex: 0.792656\n",
            "[8600]\tvalid_0's amex: 0.793151\n",
            "[8800]\tvalid_0's amex: 0.792962\n",
            "[9000]\tvalid_0's amex: 0.793398\n",
            "[9200]\tvalid_0's amex: 0.792638\n",
            "[9400]\tvalid_0's amex: 0.792942\n",
            "[9600]\tvalid_0's amex: 0.792079\n",
            "[9800]\tvalid_0's amex: 0.792346\n",
            "[10000]\tvalid_0's amex: 0.792462\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[7673]\tvalid_0's amex: 0.79377\n",
            "Training until validation scores don't improve for 4500 rounds.\n",
            "[200]\tvalid_0's amex: 0.784103\n",
            "[400]\tvalid_0's amex: 0.79123\n",
            "[600]\tvalid_0's amex: 0.792471\n",
            "[800]\tvalid_0's amex: 0.79286\n",
            "[1000]\tvalid_0's amex: 0.793172\n",
            "[1200]\tvalid_0's amex: 0.793394\n",
            "[1400]\tvalid_0's amex: 0.794072\n",
            "[1600]\tvalid_0's amex: 0.794006\n",
            "[1800]\tvalid_0's amex: 0.793628\n",
            "[2000]\tvalid_0's amex: 0.793362\n",
            "[2200]\tvalid_0's amex: 0.793356\n",
            "[2400]\tvalid_0's amex: 0.793356\n",
            "[2600]\tvalid_0's amex: 0.792714\n",
            "[2800]\tvalid_0's amex: 0.792928\n",
            "[3000]\tvalid_0's amex: 0.792818\n",
            "[3200]\tvalid_0's amex: 0.79267\n",
            "[3400]\tvalid_0's amex: 0.792156\n",
            "[3600]\tvalid_0's amex: 0.792804\n",
            "[3800]\tvalid_0's amex: 0.792454\n",
            "[4000]\tvalid_0's amex: 0.792237\n",
            "[4200]\tvalid_0's amex: 0.792725\n",
            "[4400]\tvalid_0's amex: 0.792517\n",
            "[4600]\tvalid_0's amex: 0.792738\n",
            "[4800]\tvalid_0's amex: 0.792808\n",
            "[5000]\tvalid_0's amex: 0.792854\n",
            "[5200]\tvalid_0's amex: 0.792834\n",
            "[5400]\tvalid_0's amex: 0.7925\n",
            "[5600]\tvalid_0's amex: 0.792736\n",
            "[5800]\tvalid_0's amex: 0.793306\n",
            "Early stopping, best iteration is:\n",
            "[1480]\tvalid_0's amex: 0.794621\n",
            "Training until validation scores don't improve for 4500 rounds.\n",
            "[200]\tvalid_0's amex: 0.790261\n",
            "[400]\tvalid_0's amex: 0.790713\n",
            "[600]\tvalid_0's amex: 0.790967\n",
            "[800]\tvalid_0's amex: 0.79093\n",
            "[1000]\tvalid_0's amex: 0.790598\n",
            "[1200]\tvalid_0's amex: 0.790722\n",
            "[1400]\tvalid_0's amex: 0.791541\n",
            "[1600]\tvalid_0's amex: 0.791383\n",
            "[1800]\tvalid_0's amex: 0.790808\n",
            "[2000]\tvalid_0's amex: 0.791093\n",
            "[2200]\tvalid_0's amex: 0.791546\n",
            "[2400]\tvalid_0's amex: 0.792043\n",
            "[2600]\tvalid_0's amex: 0.792423\n",
            "[2800]\tvalid_0's amex: 0.791594\n",
            "[3000]\tvalid_0's amex: 0.792108\n",
            "[3200]\tvalid_0's amex: 0.792465\n",
            "[3400]\tvalid_0's amex: 0.792457\n",
            "[3600]\tvalid_0's amex: 0.792831\n",
            "[3800]\tvalid_0's amex: 0.793448\n",
            "[4000]\tvalid_0's amex: 0.793923\n",
            "[4200]\tvalid_0's amex: 0.794072\n",
            "[4400]\tvalid_0's amex: 0.79391\n",
            "[4600]\tvalid_0's amex: 0.793796\n",
            "[4800]\tvalid_0's amex: 0.793856\n",
            "[5000]\tvalid_0's amex: 0.793775\n",
            "[5200]\tvalid_0's amex: 0.794031\n",
            "[5400]\tvalid_0's amex: 0.793526\n",
            "[5600]\tvalid_0's amex: 0.793641\n",
            "[5800]\tvalid_0's amex: 0.793835\n",
            "[6000]\tvalid_0's amex: 0.79382\n",
            "[6200]\tvalid_0's amex: 0.793773\n",
            "[6400]\tvalid_0's amex: 0.794037\n",
            "[6600]\tvalid_0's amex: 0.79324\n",
            "[6800]\tvalid_0's amex: 0.793249\n",
            "[7000]\tvalid_0's amex: 0.793525\n",
            "[7200]\tvalid_0's amex: 0.794138\n",
            "[7400]\tvalid_0's amex: 0.793843\n",
            "[7600]\tvalid_0's amex: 0.794472\n",
            "[7800]\tvalid_0's amex: 0.794732\n",
            "[8000]\tvalid_0's amex: 0.795053\n",
            "[8200]\tvalid_0's amex: 0.794445\n",
            "[8400]\tvalid_0's amex: 0.794623\n",
            "[8600]\tvalid_0's amex: 0.794187\n",
            "[8800]\tvalid_0's amex: 0.794332\n",
            "[9000]\tvalid_0's amex: 0.794287\n",
            "[9200]\tvalid_0's amex: 0.794412\n",
            "[9400]\tvalid_0's amex: 0.794556\n",
            "[9600]\tvalid_0's amex: 0.794427\n",
            "[9800]\tvalid_0's amex: 0.794\n",
            "[10000]\tvalid_0's amex: 0.794151\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[8002]\tvalid_0's amex: 0.795283\n",
            "Training until validation scores don't improve for 4500 rounds.\n",
            "[200]\tvalid_0's amex: 0.778965\n",
            "[400]\tvalid_0's amex: 0.787874\n",
            "[600]\tvalid_0's amex: 0.789133\n",
            "[800]\tvalid_0's amex: 0.790064\n",
            "[1000]\tvalid_0's amex: 0.790491\n",
            "[1200]\tvalid_0's amex: 0.791128\n",
            "[1400]\tvalid_0's amex: 0.791374\n",
            "[1600]\tvalid_0's amex: 0.791547\n",
            "[1800]\tvalid_0's amex: 0.792165\n",
            "[2000]\tvalid_0's amex: 0.791954\n",
            "[2200]\tvalid_0's amex: 0.792363\n",
            "[2400]\tvalid_0's amex: 0.79274\n",
            "[2600]\tvalid_0's amex: 0.792767\n",
            "[2800]\tvalid_0's amex: 0.793208\n",
            "[3000]\tvalid_0's amex: 0.793563\n",
            "[3200]\tvalid_0's amex: 0.79379\n",
            "[3400]\tvalid_0's amex: 0.793588\n",
            "[3600]\tvalid_0's amex: 0.793299\n",
            "[3800]\tvalid_0's amex: 0.793591\n",
            "[4000]\tvalid_0's amex: 0.79381\n",
            "[4200]\tvalid_0's amex: 0.793887\n",
            "[4400]\tvalid_0's amex: 0.794172\n",
            "[4600]\tvalid_0's amex: 0.794226\n",
            "[4800]\tvalid_0's amex: 0.793715\n",
            "[5000]\tvalid_0's amex: 0.79364\n",
            "[5200]\tvalid_0's amex: 0.793651\n",
            "[5400]\tvalid_0's amex: 0.793325\n",
            "[5600]\tvalid_0's amex: 0.793926\n",
            "[5800]\tvalid_0's amex: 0.793481\n",
            "[6000]\tvalid_0's amex: 0.793679\n",
            "[6200]\tvalid_0's amex: 0.794106\n",
            "[6400]\tvalid_0's amex: 0.794005\n",
            "[6600]\tvalid_0's amex: 0.794309\n",
            "[6800]\tvalid_0's amex: 0.794392\n",
            "[7000]\tvalid_0's amex: 0.794427\n",
            "[7200]\tvalid_0's amex: 0.793997\n",
            "[7400]\tvalid_0's amex: 0.793552\n",
            "[7600]\tvalid_0's amex: 0.79401\n",
            "[7800]\tvalid_0's amex: 0.794133\n",
            "[8000]\tvalid_0's amex: 0.79422\n",
            "[8200]\tvalid_0's amex: 0.793757\n",
            "[8400]\tvalid_0's amex: 0.79399\n",
            "[8600]\tvalid_0's amex: 0.794559\n",
            "[8800]\tvalid_0's amex: 0.794369\n",
            "[9000]\tvalid_0's amex: 0.793823\n",
            "[9200]\tvalid_0's amex: 0.794149\n",
            "[9400]\tvalid_0's amex: 0.794401\n",
            "[9600]\tvalid_0's amex: 0.79444\n",
            "[9800]\tvalid_0's amex: 0.794436\n",
            "[10000]\tvalid_0's amex: 0.794096\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[9655]\tvalid_0's amex: 0.7948\n",
            "Training until validation scores don't improve for 4500 rounds.\n",
            "[200]\tvalid_0's amex: 0.789243\n",
            "[400]\tvalid_0's amex: 0.79082\n",
            "[600]\tvalid_0's amex: 0.79054\n",
            "[800]\tvalid_0's amex: 0.790437\n",
            "[1000]\tvalid_0's amex: 0.790703\n",
            "[1200]\tvalid_0's amex: 0.790626\n",
            "[1400]\tvalid_0's amex: 0.788194\n",
            "[1600]\tvalid_0's amex: 0.788682\n",
            "[1800]\tvalid_0's amex: 0.789272\n",
            "[2000]\tvalid_0's amex: 0.789272\n",
            "[2200]\tvalid_0's amex: 0.789669\n",
            "[2400]\tvalid_0's amex: 0.790222\n",
            "[2600]\tvalid_0's amex: 0.78989\n",
            "[2800]\tvalid_0's amex: 0.790313\n",
            "[3000]\tvalid_0's amex: 0.790022\n",
            "[3200]\tvalid_0's amex: 0.789471\n",
            "[3400]\tvalid_0's amex: 0.78944\n",
            "[3600]\tvalid_0's amex: 0.789705\n",
            "[3800]\tvalid_0's amex: 0.789664\n",
            "[4000]\tvalid_0's amex: 0.790391\n",
            "[4200]\tvalid_0's amex: 0.790179\n",
            "[4400]\tvalid_0's amex: 0.791206\n",
            "[4600]\tvalid_0's amex: 0.790832\n",
            "[4800]\tvalid_0's amex: 0.791228\n",
            "[5000]\tvalid_0's amex: 0.791181\n",
            "[5200]\tvalid_0's amex: 0.79122\n",
            "[5400]\tvalid_0's amex: 0.790941\n",
            "[5600]\tvalid_0's amex: 0.791252\n",
            "Early stopping, best iteration is:\n",
            "[1106]\tvalid_0's amex: 0.791831\n",
            "Training until validation scores don't improve for 4500 rounds.\n",
            "[200]\tvalid_0's amex: 0.787207\n",
            "[400]\tvalid_0's amex: 0.791941\n",
            "[600]\tvalid_0's amex: 0.793815\n",
            "[800]\tvalid_0's amex: 0.793371\n",
            "[1000]\tvalid_0's amex: 0.793775\n",
            "[1200]\tvalid_0's amex: 0.794045\n",
            "[1400]\tvalid_0's amex: 0.794244\n",
            "[1600]\tvalid_0's amex: 0.794386\n",
            "[1800]\tvalid_0's amex: 0.794943\n",
            "[2000]\tvalid_0's amex: 0.795368\n",
            "[2200]\tvalid_0's amex: 0.794778\n",
            "[2400]\tvalid_0's amex: 0.794458\n",
            "[2600]\tvalid_0's amex: 0.795114\n",
            "[2800]\tvalid_0's amex: 0.794863\n",
            "[3000]\tvalid_0's amex: 0.794956\n",
            "[3200]\tvalid_0's amex: 0.794348\n",
            "[3400]\tvalid_0's amex: 0.793901\n",
            "[3600]\tvalid_0's amex: 0.79381\n",
            "[3800]\tvalid_0's amex: 0.793967\n",
            "[4000]\tvalid_0's amex: 0.794713\n",
            "[4200]\tvalid_0's amex: 0.794988\n",
            "[4400]\tvalid_0's amex: 0.794972\n",
            "[4600]\tvalid_0's amex: 0.795226\n",
            "[4800]\tvalid_0's amex: 0.795204\n",
            "[5000]\tvalid_0's amex: 0.795179\n",
            "[5200]\tvalid_0's amex: 0.794972\n",
            "[5400]\tvalid_0's amex: 0.795163\n",
            "[5600]\tvalid_0's amex: 0.794744\n",
            "[5800]\tvalid_0's amex: 0.794806\n",
            "[6000]\tvalid_0's amex: 0.794905\n",
            "[6200]\tvalid_0's amex: 0.794823\n",
            "[6400]\tvalid_0's amex: 0.79482\n",
            "[6600]\tvalid_0's amex: 0.794388\n",
            "[6800]\tvalid_0's amex: 0.793545\n",
            "[7000]\tvalid_0's amex: 0.793841\n",
            "[7200]\tvalid_0's amex: 0.793993\n",
            "[7400]\tvalid_0's amex: 0.793311\n",
            "[7600]\tvalid_0's amex: 0.794202\n",
            "[7800]\tvalid_0's amex: 0.7946\n",
            "[8000]\tvalid_0's amex: 0.794158\n",
            "[8200]\tvalid_0's amex: 0.79443\n",
            "[8400]\tvalid_0's amex: 0.79447\n",
            "[8600]\tvalid_0's amex: 0.794695\n",
            "[8800]\tvalid_0's amex: 0.794687\n",
            "[9000]\tvalid_0's amex: 0.794871\n",
            "[9200]\tvalid_0's amex: 0.794866\n",
            "[9400]\tvalid_0's amex: 0.795701\n",
            "[9600]\tvalid_0's amex: 0.795292\n",
            "[9800]\tvalid_0's amex: 0.795207\n",
            "[10000]\tvalid_0's amex: 0.795166\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[9504]\tvalid_0's amex: 0.795889\n",
            "Training until validation scores don't improve for 4500 rounds.\n",
            "[200]\tvalid_0's amex: 0.785991\n",
            "[400]\tvalid_0's amex: 0.783895\n",
            "[600]\tvalid_0's amex: 0.784624\n",
            "[800]\tvalid_0's amex: 0.784415\n",
            "[1000]\tvalid_0's amex: 0.785131\n",
            "[1200]\tvalid_0's amex: 0.785061\n",
            "[1400]\tvalid_0's amex: 0.784671\n",
            "[1600]\tvalid_0's amex: 0.784901\n",
            "[1800]\tvalid_0's amex: 0.785852\n",
            "[2000]\tvalid_0's amex: 0.787332\n",
            "[2200]\tvalid_0's amex: 0.787347\n",
            "[2400]\tvalid_0's amex: 0.78692\n",
            "[2600]\tvalid_0's amex: 0.788167\n",
            "[2800]\tvalid_0's amex: 0.788348\n",
            "[3000]\tvalid_0's amex: 0.788989\n",
            "[3200]\tvalid_0's amex: 0.788576\n",
            "[3400]\tvalid_0's amex: 0.788426\n",
            "[3600]\tvalid_0's amex: 0.789706\n",
            "[3800]\tvalid_0's amex: 0.788795\n",
            "[4000]\tvalid_0's amex: 0.789209\n",
            "[4200]\tvalid_0's amex: 0.788968\n",
            "[4400]\tvalid_0's amex: 0.78993\n",
            "[4600]\tvalid_0's amex: 0.789138\n",
            "[4800]\tvalid_0's amex: 0.78975\n",
            "[5000]\tvalid_0's amex: 0.789489\n",
            "[5200]\tvalid_0's amex: 0.789181\n",
            "[5400]\tvalid_0's amex: 0.78878\n",
            "[5600]\tvalid_0's amex: 0.78961\n",
            "[5800]\tvalid_0's amex: 0.790104\n",
            "[6000]\tvalid_0's amex: 0.789934\n",
            "[6200]\tvalid_0's amex: 0.790091\n",
            "[6400]\tvalid_0's amex: 0.790064\n",
            "[6600]\tvalid_0's amex: 0.790167\n",
            "[6800]\tvalid_0's amex: 0.789932\n",
            "[7000]\tvalid_0's amex: 0.790107\n",
            "[7200]\tvalid_0's amex: 0.789984\n",
            "[7400]\tvalid_0's amex: 0.790105\n",
            "[7600]\tvalid_0's amex: 0.790269\n",
            "[7800]\tvalid_0's amex: 0.790342\n",
            "[8000]\tvalid_0's amex: 0.790137\n",
            "[8200]\tvalid_0's amex: 0.790258\n",
            "[8400]\tvalid_0's amex: 0.790702\n",
            "[8600]\tvalid_0's amex: 0.790855\n",
            "[8800]\tvalid_0's amex: 0.790896\n",
            "[9000]\tvalid_0's amex: 0.790889\n",
            "[9200]\tvalid_0's amex: 0.791148\n",
            "[9400]\tvalid_0's amex: 0.791129\n",
            "[9600]\tvalid_0's amex: 0.79101\n",
            "[9800]\tvalid_0's amex: 0.790945\n",
            "[10000]\tvalid_0's amex: 0.791074\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[9979]\tvalid_0's amex: 0.791514\n",
            "Training until validation scores don't improve for 4500 rounds.\n",
            "[200]\tvalid_0's amex: 0.77867\n",
            "[400]\tvalid_0's amex: 0.788422\n",
            "[600]\tvalid_0's amex: 0.790574\n",
            "[800]\tvalid_0's amex: 0.792497\n",
            "[1000]\tvalid_0's amex: 0.793146\n",
            "[1200]\tvalid_0's amex: 0.793265\n",
            "[1400]\tvalid_0's amex: 0.793603\n",
            "[1600]\tvalid_0's amex: 0.793675\n",
            "[1800]\tvalid_0's amex: 0.793745\n",
            "[2000]\tvalid_0's amex: 0.793166\n",
            "[2200]\tvalid_0's amex: 0.79308\n",
            "[2400]\tvalid_0's amex: 0.793873\n",
            "[2600]\tvalid_0's amex: 0.793842\n",
            "[2800]\tvalid_0's amex: 0.793919\n",
            "[3000]\tvalid_0's amex: 0.794407\n",
            "[3200]\tvalid_0's amex: 0.793993\n",
            "[3400]\tvalid_0's amex: 0.793854\n",
            "[3600]\tvalid_0's amex: 0.793946\n",
            "[3800]\tvalid_0's amex: 0.79442\n",
            "[4000]\tvalid_0's amex: 0.793783\n",
            "[4200]\tvalid_0's amex: 0.794097\n",
            "[4400]\tvalid_0's amex: 0.794047\n",
            "[4600]\tvalid_0's amex: 0.793824\n",
            "[4800]\tvalid_0's amex: 0.793989\n",
            "[5000]\tvalid_0's amex: 0.794092\n",
            "[5200]\tvalid_0's amex: 0.794134\n",
            "[5400]\tvalid_0's amex: 0.794071\n",
            "[5600]\tvalid_0's amex: 0.79392\n",
            "[5800]\tvalid_0's amex: 0.793779\n",
            "[6000]\tvalid_0's amex: 0.793252\n",
            "[6200]\tvalid_0's amex: 0.793464\n",
            "[6400]\tvalid_0's amex: 0.793672\n",
            "[6600]\tvalid_0's amex: 0.793732\n",
            "[6800]\tvalid_0's amex: 0.794343\n",
            "[7000]\tvalid_0's amex: 0.794255\n",
            "[7200]\tvalid_0's amex: 0.793838\n",
            "[7400]\tvalid_0's amex: 0.794133\n",
            "[7600]\tvalid_0's amex: 0.79334\n",
            "[7800]\tvalid_0's amex: 0.794174\n",
            "[8000]\tvalid_0's amex: 0.793867\n",
            "[8200]\tvalid_0's amex: 0.793804\n",
            "[8400]\tvalid_0's amex: 0.79364\n",
            "[8600]\tvalid_0's amex: 0.79366\n",
            "[8800]\tvalid_0's amex: 0.793685\n",
            "[9000]\tvalid_0's amex: 0.793272\n",
            "[9200]\tvalid_0's amex: 0.793422\n",
            "[9400]\tvalid_0's amex: 0.793419\n",
            "[9600]\tvalid_0's amex: 0.79325\n",
            "[9800]\tvalid_0's amex: 0.79346\n",
            "[10000]\tvalid_0's amex: 0.793268\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[6864]\tvalid_0's amex: 0.794677\n",
            "Training until validation scores don't improve for 4500 rounds.\n",
            "[200]\tvalid_0's amex: 0.787561\n",
            "[400]\tvalid_0's amex: 0.791104\n",
            "[600]\tvalid_0's amex: 0.792908\n",
            "[800]\tvalid_0's amex: 0.793979\n",
            "[1000]\tvalid_0's amex: 0.792114\n",
            "[1200]\tvalid_0's amex: 0.792475\n",
            "[1400]\tvalid_0's amex: 0.792496\n",
            "[1600]\tvalid_0's amex: 0.79234\n",
            "[1800]\tvalid_0's amex: 0.792937\n",
            "[2000]\tvalid_0's amex: 0.79285\n",
            "[2200]\tvalid_0's amex: 0.792452\n",
            "[2400]\tvalid_0's amex: 0.792584\n",
            "[2600]\tvalid_0's amex: 0.791867\n",
            "[2800]\tvalid_0's amex: 0.79216\n",
            "[3000]\tvalid_0's amex: 0.792828\n",
            "[3200]\tvalid_0's amex: 0.792395\n",
            "[3400]\tvalid_0's amex: 0.793807\n",
            "[3600]\tvalid_0's amex: 0.792804\n",
            "[3800]\tvalid_0's amex: 0.792883\n",
            "[4000]\tvalid_0's amex: 0.792568\n",
            "[4200]\tvalid_0's amex: 0.792798\n",
            "[4400]\tvalid_0's amex: 0.791813\n",
            "[4600]\tvalid_0's amex: 0.791843\n",
            "[4800]\tvalid_0's amex: 0.792258\n",
            "[5000]\tvalid_0's amex: 0.793142\n",
            "[5200]\tvalid_0's amex: 0.792823\n",
            "Early stopping, best iteration is:\n",
            "[800]\tvalid_0's amex: 0.793979\n",
            "Training until validation scores don't improve for 4500 rounds.\n",
            "[200]\tvalid_0's amex: 0.785197\n",
            "[400]\tvalid_0's amex: 0.792222\n",
            "[600]\tvalid_0's amex: 0.793202\n",
            "[800]\tvalid_0's amex: 0.793668\n",
            "[1000]\tvalid_0's amex: 0.792799\n",
            "[1200]\tvalid_0's amex: 0.792384\n",
            "[1400]\tvalid_0's amex: 0.792955\n",
            "[1600]\tvalid_0's amex: 0.793152\n",
            "[1800]\tvalid_0's amex: 0.79267\n",
            "[2000]\tvalid_0's amex: 0.79334\n",
            "[2200]\tvalid_0's amex: 0.793619\n",
            "[2400]\tvalid_0's amex: 0.793127\n",
            "[2600]\tvalid_0's amex: 0.793168\n",
            "[2800]\tvalid_0's amex: 0.793287\n",
            "[3000]\tvalid_0's amex: 0.792788\n",
            "[3200]\tvalid_0's amex: 0.793752\n",
            "[3400]\tvalid_0's amex: 0.793018\n",
            "[3600]\tvalid_0's amex: 0.792752\n",
            "[3800]\tvalid_0's amex: 0.793085\n",
            "[4000]\tvalid_0's amex: 0.793286\n",
            "[4200]\tvalid_0's amex: 0.793226\n",
            "[4400]\tvalid_0's amex: 0.793026\n",
            "[4600]\tvalid_0's amex: 0.793063\n",
            "[4800]\tvalid_0's amex: 0.793191\n",
            "[5000]\tvalid_0's amex: 0.792805\n",
            "[5200]\tvalid_0's amex: 0.793087\n",
            "Early stopping, best iteration is:\n",
            "[837]\tvalid_0's amex: 0.794095\n",
            "Training until validation scores don't improve for 4500 rounds.\n",
            "[200]\tvalid_0's amex: 0.789584\n",
            "[400]\tvalid_0's amex: 0.791096\n",
            "[600]\tvalid_0's amex: 0.792174\n",
            "[800]\tvalid_0's amex: 0.791313\n",
            "[1000]\tvalid_0's amex: 0.790979\n",
            "[1200]\tvalid_0's amex: 0.79027\n",
            "[1400]\tvalid_0's amex: 0.790387\n",
            "[1600]\tvalid_0's amex: 0.790635\n",
            "[1800]\tvalid_0's amex: 0.790443\n",
            "[2000]\tvalid_0's amex: 0.789634\n",
            "[2200]\tvalid_0's amex: 0.790765\n",
            "[2400]\tvalid_0's amex: 0.789959\n",
            "[2600]\tvalid_0's amex: 0.790773\n",
            "[2800]\tvalid_0's amex: 0.790379\n",
            "[3000]\tvalid_0's amex: 0.7912\n",
            "[3200]\tvalid_0's amex: 0.7919\n",
            "[3400]\tvalid_0's amex: 0.791895\n",
            "[3600]\tvalid_0's amex: 0.791777\n",
            "[3800]\tvalid_0's amex: 0.791579\n",
            "[4000]\tvalid_0's amex: 0.790949\n",
            "[4200]\tvalid_0's amex: 0.791594\n",
            "[4400]\tvalid_0's amex: 0.79165\n",
            "[4600]\tvalid_0's amex: 0.791354\n",
            "[4800]\tvalid_0's amex: 0.791358\n",
            "[5000]\tvalid_0's amex: 0.791482\n",
            "Early stopping, best iteration is:\n",
            "[664]\tvalid_0's amex: 0.79261\n",
            "Training until validation scores don't improve for 4500 rounds.\n",
            "[200]\tvalid_0's amex: 0.780825\n",
            "[400]\tvalid_0's amex: 0.790459\n",
            "[600]\tvalid_0's amex: 0.791618\n",
            "[800]\tvalid_0's amex: 0.792161\n",
            "[1000]\tvalid_0's amex: 0.792944\n",
            "[1200]\tvalid_0's amex: 0.793457\n",
            "[1400]\tvalid_0's amex: 0.794031\n",
            "[1600]\tvalid_0's amex: 0.793279\n",
            "[1800]\tvalid_0's amex: 0.79335\n",
            "[2000]\tvalid_0's amex: 0.794052\n",
            "[2200]\tvalid_0's amex: 0.793787\n",
            "[2400]\tvalid_0's amex: 0.793683\n",
            "[2600]\tvalid_0's amex: 0.79407\n",
            "[2800]\tvalid_0's amex: 0.794395\n",
            "[3000]\tvalid_0's amex: 0.794499\n",
            "[3200]\tvalid_0's amex: 0.794095\n",
            "[3400]\tvalid_0's amex: 0.794274\n",
            "[3600]\tvalid_0's amex: 0.794201\n",
            "[3800]\tvalid_0's amex: 0.793669\n",
            "[4000]\tvalid_0's amex: 0.793649\n",
            "[4200]\tvalid_0's amex: 0.793654\n",
            "[4400]\tvalid_0's amex: 0.793772\n",
            "[4600]\tvalid_0's amex: 0.794203\n",
            "[4800]\tvalid_0's amex: 0.794399\n",
            "[5000]\tvalid_0's amex: 0.793955\n",
            "[5200]\tvalid_0's amex: 0.794104\n",
            "[5400]\tvalid_0's amex: 0.79408\n",
            "[5600]\tvalid_0's amex: 0.794519\n",
            "[5800]\tvalid_0's amex: 0.794899\n",
            "[6000]\tvalid_0's amex: 0.794881\n",
            "[6200]\tvalid_0's amex: 0.795173\n",
            "[6400]\tvalid_0's amex: 0.794513\n",
            "[6600]\tvalid_0's amex: 0.79483\n",
            "[6800]\tvalid_0's amex: 0.794448\n",
            "[7000]\tvalid_0's amex: 0.795072\n",
            "[7200]\tvalid_0's amex: 0.794925\n",
            "[7400]\tvalid_0's amex: 0.794504\n",
            "[7600]\tvalid_0's amex: 0.79481\n",
            "[7800]\tvalid_0's amex: 0.794682\n",
            "[8000]\tvalid_0's amex: 0.794439\n",
            "[8200]\tvalid_0's amex: 0.795077\n",
            "[8400]\tvalid_0's amex: 0.794263\n",
            "[8600]\tvalid_0's amex: 0.794736\n",
            "[8800]\tvalid_0's amex: 0.794425\n",
            "[9000]\tvalid_0's amex: 0.794582\n",
            "[9200]\tvalid_0's amex: 0.794858\n",
            "[9400]\tvalid_0's amex: 0.79428\n",
            "[9600]\tvalid_0's amex: 0.794348\n",
            "[9800]\tvalid_0's amex: 0.794817\n",
            "[10000]\tvalid_0's amex: 0.794407\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5774]\tvalid_0's amex: 0.795359\n",
            "Training until validation scores don't improve for 4500 rounds.\n",
            "[200]\tvalid_0's amex: 0.790043\n",
            "[400]\tvalid_0's amex: 0.792669\n",
            "[600]\tvalid_0's amex: 0.793186\n",
            "[800]\tvalid_0's amex: 0.792823\n",
            "[1000]\tvalid_0's amex: 0.792958\n",
            "[1200]\tvalid_0's amex: 0.791928\n",
            "[1400]\tvalid_0's amex: 0.792067\n",
            "[1600]\tvalid_0's amex: 0.79188\n",
            "[1800]\tvalid_0's amex: 0.791575\n",
            "[2000]\tvalid_0's amex: 0.792329\n",
            "[2200]\tvalid_0's amex: 0.792372\n",
            "[2400]\tvalid_0's amex: 0.79241\n",
            "[2600]\tvalid_0's amex: 0.792925\n",
            "[2800]\tvalid_0's amex: 0.792245\n",
            "[3000]\tvalid_0's amex: 0.793082\n",
            "[3200]\tvalid_0's amex: 0.792599\n",
            "[3400]\tvalid_0's amex: 0.792048\n",
            "[3600]\tvalid_0's amex: 0.792725\n",
            "[3800]\tvalid_0's amex: 0.793112\n",
            "[4000]\tvalid_0's amex: 0.792816\n",
            "[4200]\tvalid_0's amex: 0.792435\n",
            "[4400]\tvalid_0's amex: 0.792907\n",
            "[4600]\tvalid_0's amex: 0.792479\n",
            "[4800]\tvalid_0's amex: 0.793001\n",
            "Early stopping, best iteration is:\n",
            "[414]\tvalid_0's amex: 0.793602\n",
            "Training until validation scores don't improve for 4500 rounds.\n",
            "[200]\tvalid_0's amex: 0.773644\n",
            "[400]\tvalid_0's amex: 0.783184\n",
            "[600]\tvalid_0's amex: 0.788218\n",
            "[800]\tvalid_0's amex: 0.789546\n",
            "[1000]\tvalid_0's amex: 0.790334\n",
            "[1200]\tvalid_0's amex: 0.790904\n",
            "[1400]\tvalid_0's amex: 0.791659\n",
            "[1600]\tvalid_0's amex: 0.791751\n",
            "[1800]\tvalid_0's amex: 0.791949\n",
            "[2000]\tvalid_0's amex: 0.791767\n",
            "[2200]\tvalid_0's amex: 0.792434\n",
            "[2400]\tvalid_0's amex: 0.792993\n",
            "[2600]\tvalid_0's amex: 0.793207\n",
            "[2800]\tvalid_0's amex: 0.792748\n",
            "[3000]\tvalid_0's amex: 0.793006\n",
            "[3200]\tvalid_0's amex: 0.792847\n",
            "[3400]\tvalid_0's amex: 0.793233\n",
            "[3600]\tvalid_0's amex: 0.793037\n",
            "[3800]\tvalid_0's amex: 0.79292\n",
            "[4000]\tvalid_0's amex: 0.793011\n",
            "[4200]\tvalid_0's amex: 0.793055\n",
            "[4400]\tvalid_0's amex: 0.792875\n",
            "[4600]\tvalid_0's amex: 0.792941\n",
            "[4800]\tvalid_0's amex: 0.792972\n",
            "[5000]\tvalid_0's amex: 0.792905\n",
            "[5200]\tvalid_0's amex: 0.792882\n",
            "[5400]\tvalid_0's amex: 0.793494\n",
            "[5600]\tvalid_0's amex: 0.793518\n",
            "[5800]\tvalid_0's amex: 0.793226\n",
            "[6000]\tvalid_0's amex: 0.793343\n",
            "[6200]\tvalid_0's amex: 0.793588\n",
            "[6400]\tvalid_0's amex: 0.793306\n",
            "[6600]\tvalid_0's amex: 0.793951\n",
            "[6800]\tvalid_0's amex: 0.794034\n",
            "[7000]\tvalid_0's amex: 0.79417\n",
            "[7200]\tvalid_0's amex: 0.794397\n",
            "[7400]\tvalid_0's amex: 0.794613\n",
            "[7600]\tvalid_0's amex: 0.793861\n",
            "[7800]\tvalid_0's amex: 0.793822\n",
            "[8000]\tvalid_0's amex: 0.793822\n",
            "[8200]\tvalid_0's amex: 0.793903\n",
            "[8400]\tvalid_0's amex: 0.794063\n",
            "[8600]\tvalid_0's amex: 0.794026\n",
            "[8800]\tvalid_0's amex: 0.793982\n",
            "[9000]\tvalid_0's amex: 0.794361\n",
            "[9200]\tvalid_0's amex: 0.794231\n",
            "[9400]\tvalid_0's amex: 0.79388\n",
            "[9600]\tvalid_0's amex: 0.794159\n",
            "[9800]\tvalid_0's amex: 0.794244\n",
            "[10000]\tvalid_0's amex: 0.794056\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[7386]\tvalid_0's amex: 0.794822\n",
            "Training until validation scores don't improve for 4500 rounds.\n",
            "[200]\tvalid_0's amex: 0.786083\n",
            "[400]\tvalid_0's amex: 0.791626\n",
            "[600]\tvalid_0's amex: 0.79287\n",
            "[800]\tvalid_0's amex: 0.793355\n",
            "[1000]\tvalid_0's amex: 0.79379\n",
            "[1200]\tvalid_0's amex: 0.79297\n",
            "[1400]\tvalid_0's amex: 0.792901\n",
            "[1600]\tvalid_0's amex: 0.793278\n",
            "[1800]\tvalid_0's amex: 0.793049\n",
            "[2000]\tvalid_0's amex: 0.792969\n",
            "[2200]\tvalid_0's amex: 0.792338\n",
            "[2400]\tvalid_0's amex: 0.791874\n",
            "[2600]\tvalid_0's amex: 0.792296\n",
            "[2800]\tvalid_0's amex: 0.79128\n",
            "[3000]\tvalid_0's amex: 0.791537\n",
            "[3200]\tvalid_0's amex: 0.791167\n",
            "[3400]\tvalid_0's amex: 0.79162\n",
            "[3600]\tvalid_0's amex: 0.79138\n",
            "[3800]\tvalid_0's amex: 0.791241\n",
            "[4000]\tvalid_0's amex: 0.79177\n",
            "[4200]\tvalid_0's amex: 0.791487\n",
            "[4400]\tvalid_0's amex: 0.79204\n",
            "[4600]\tvalid_0's amex: 0.791779\n",
            "[4800]\tvalid_0's amex: 0.792192\n",
            "[5000]\tvalid_0's amex: 0.792307\n",
            "[5200]\tvalid_0's amex: 0.791758\n",
            "[5400]\tvalid_0's amex: 0.791924\n",
            "Early stopping, best iteration is:\n",
            "[1051]\tvalid_0's amex: 0.794232\n",
            "Training until validation scores don't improve for 4500 rounds.\n",
            "[200]\tvalid_0's amex: 0.791159\n",
            "[400]\tvalid_0's amex: 0.793762\n",
            "[600]\tvalid_0's amex: 0.793075\n",
            "[800]\tvalid_0's amex: 0.792952\n",
            "[1000]\tvalid_0's amex: 0.792558\n",
            "[1200]\tvalid_0's amex: 0.792603\n",
            "[1400]\tvalid_0's amex: 0.792199\n",
            "[1600]\tvalid_0's amex: 0.791667\n",
            "[1800]\tvalid_0's amex: 0.791441\n",
            "[2000]\tvalid_0's amex: 0.791191\n",
            "[2200]\tvalid_0's amex: 0.791317\n",
            "[2400]\tvalid_0's amex: 0.791571\n",
            "[2600]\tvalid_0's amex: 0.791307\n",
            "[2800]\tvalid_0's amex: 0.791243\n",
            "[3000]\tvalid_0's amex: 0.79002\n",
            "[3200]\tvalid_0's amex: 0.790667\n",
            "[3400]\tvalid_0's amex: 0.792032\n",
            "[3600]\tvalid_0's amex: 0.791849\n",
            "[3800]\tvalid_0's amex: 0.791288\n",
            "[4000]\tvalid_0's amex: 0.791248\n",
            "[4200]\tvalid_0's amex: 0.791962\n",
            "[4400]\tvalid_0's amex: 0.791832\n",
            "[4600]\tvalid_0's amex: 0.792248\n",
            "[4800]\tvalid_0's amex: 0.791942\n",
            "Early stopping, best iteration is:\n",
            "[378]\tvalid_0's amex: 0.794203\n",
            "Training until validation scores don't improve for 4500 rounds.\n",
            "[200]\tvalid_0's amex: 0.779227\n",
            "[400]\tvalid_0's amex: 0.790794\n",
            "[600]\tvalid_0's amex: 0.791886\n",
            "[800]\tvalid_0's amex: 0.793914\n",
            "[1000]\tvalid_0's amex: 0.793649\n",
            "[1200]\tvalid_0's amex: 0.794508\n",
            "[1400]\tvalid_0's amex: 0.795023\n",
            "[1600]\tvalid_0's amex: 0.794439\n",
            "[1800]\tvalid_0's amex: 0.795063\n",
            "[2000]\tvalid_0's amex: 0.795079\n",
            "[2200]\tvalid_0's amex: 0.794891\n",
            "[2400]\tvalid_0's amex: 0.795275\n",
            "[2600]\tvalid_0's amex: 0.794559\n",
            "[2800]\tvalid_0's amex: 0.794741\n",
            "[3000]\tvalid_0's amex: 0.794662\n",
            "[3200]\tvalid_0's amex: 0.794773\n",
            "[3400]\tvalid_0's amex: 0.79517\n",
            "[3600]\tvalid_0's amex: 0.794912\n",
            "[3800]\tvalid_0's amex: 0.79524\n",
            "[4000]\tvalid_0's amex: 0.795619\n",
            "[4200]\tvalid_0's amex: 0.795408\n",
            "[4400]\tvalid_0's amex: 0.7952\n",
            "[4600]\tvalid_0's amex: 0.795024\n",
            "[4800]\tvalid_0's amex: 0.7956\n",
            "[5000]\tvalid_0's amex: 0.795263\n",
            "[5200]\tvalid_0's amex: 0.795489\n",
            "[5400]\tvalid_0's amex: 0.795548\n",
            "[5600]\tvalid_0's amex: 0.795462\n",
            "[5800]\tvalid_0's amex: 0.795486\n",
            "[6000]\tvalid_0's amex: 0.795727\n",
            "[6200]\tvalid_0's amex: 0.795887\n",
            "[6400]\tvalid_0's amex: 0.795778\n",
            "[6600]\tvalid_0's amex: 0.795631\n",
            "[6800]\tvalid_0's amex: 0.795499\n",
            "[7000]\tvalid_0's amex: 0.795346\n",
            "[7200]\tvalid_0's amex: 0.79498\n",
            "[7400]\tvalid_0's amex: 0.795131\n",
            "[7600]\tvalid_0's amex: 0.795533\n",
            "[7800]\tvalid_0's amex: 0.796293\n",
            "[8000]\tvalid_0's amex: 0.795838\n",
            "[8200]\tvalid_0's amex: 0.795849\n",
            "[8400]\tvalid_0's amex: 0.795685\n",
            "[8600]\tvalid_0's amex: 0.795727\n",
            "[8800]\tvalid_0's amex: 0.795534\n",
            "[9000]\tvalid_0's amex: 0.795966\n",
            "[9200]\tvalid_0's amex: 0.795964\n",
            "[9400]\tvalid_0's amex: 0.79571\n",
            "[9600]\tvalid_0's amex: 0.795978\n",
            "[9800]\tvalid_0's amex: 0.795984\n",
            "[10000]\tvalid_0's amex: 0.796353\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[9976]\tvalid_0's amex: 0.796601\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# display best parameters\n",
        "study.best_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUkFVa1wBRLg",
        "outputId": "386be29f-dfcf-4922-8a07-3013abc60e42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bagging_fraction': 0.4591871995031453,\n",
              " 'feature_fraction': 0.05944201683712933,\n",
              " 'learning_rate': 0.022770370427204846,\n",
              " 'min_data_in_leaf': 120,\n",
              " 'num_leaves': 60}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualise the prediction scores for trials\n",
        "optuna.visualization.plot_optimization_history(study)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "5Jaf_y3tBRa6",
        "outputId": "d2f09b8b-040d-4c13-bcce-6c0a8c2cb926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"7c2c170a-9ac2-4e2c-a522-efa262cef229\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7c2c170a-9ac2-4e2c-a522-efa262cef229\")) {                    Plotly.newPlot(                        \"7c2c170a-9ac2-4e2c-a522-efa262cef229\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31],\"y\":[0.7951908122787738,0.7916691687997688,0.7952277949435803,0.7948874231767353,0.7918008531201574,0.7957592445039456,0.7957028249674201,0.7908866467307051,0.7959791628486299,0.7963595289737755,0.7923682709821112,0.7935965942744176,0.7953166252716038,0.7937700408037158,0.794621492896779,0.7952832176626796,0.7948003152072503,0.7918306988857373,0.7958892403670812,0.7915139629264304,0.7946765310227036,0.7939787749138371,0.7940949518296788,0.7926102922050962,0.7953588410408238,0.7936016328457576,0.7948219001707948,0.7942319457948611,0.7942030689600568,0.7966013353076016],\"type\":\"scatter\"},{\"name\":\"Best Value\",\"x\":[2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31],\"y\":[0.7951908122787738,0.7951908122787738,0.7952277949435803,0.7952277949435803,0.7952277949435803,0.7957592445039456,0.7957592445039456,0.7957592445039456,0.7959791628486299,0.7963595289737755,0.7963595289737755,0.7963595289737755,0.7963595289737755,0.7963595289737755,0.7963595289737755,0.7963595289737755,0.7963595289737755,0.7963595289737755,0.7963595289737755,0.7963595289737755,0.7963595289737755,0.7963595289737755,0.7963595289737755,0.7963595289737755,0.7963595289737755,0.7963595289737755,0.7963595289737755,0.7963595289737755,0.7963595289737755,0.7966013353076016],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('7c2c170a-9ac2-4e2c-a522-efa262cef229');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualise the prediction scores as a function of parameters\n",
        "optuna.visualization.plot_slice(study)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "cTGv8RqABRkn",
        "outputId": "f8fa4a4f-cdab-4c22-ab85-59e4d404d99d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"7edf564c-7a0a-4eee-96c9-27cb4202d19f\" class=\"plotly-graph-div\" style=\"height:525px; width:1500px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7edf564c-7a0a-4eee-96c9-27cb4202d19f\")) {                    Plotly.newPlot(                        \"7edf564c-7a0a-4eee-96c9-27cb4202d19f\",                        [{\"marker\":{\"color\":[2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":true},\"mode\":\"markers\",\"showlegend\":false,\"x\":[0.7879151119102458,0.6643844993381367,0.675755875529661,0.4908809567549495,0.7238143789392372,0.5419959804541153,0.413861897820499,0.7087118348275178,0.5840655464355625,0.46585126213729683,0.40694996378931697,0.4884059770088198,0.5890557445936013,0.5784398511637798,0.46938264812786595,0.5307531512285185,0.617487342755873,0.4447243245338851,0.5314589504167534,0.6223383108750984,0.4490452175721455,0.5174629088040189,0.5531579379565388,0.5097509357064156,0.437347829274578,0.5996104752098691,0.4800927374839161,0.560404606512988,0.5136208276830769,0.4591871995031453],\"y\":[0.7951908122787738,0.7916691687997688,0.7952277949435803,0.7948874231767353,0.7918008531201574,0.7957592445039456,0.7957028249674201,0.7908866467307051,0.7959791628486299,0.7963595289737755,0.7923682709821112,0.7935965942744176,0.7953166252716038,0.7937700408037158,0.794621492896779,0.7952832176626796,0.7948003152072503,0.7918306988857373,0.7958892403670812,0.7915139629264304,0.7946765310227036,0.7939787749138371,0.7940949518296788,0.7926102922050962,0.7953588410408238,0.7936016328457576,0.7948219001707948,0.7942319457948611,0.7942030689600568,0.7966013353076016],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"marker\":{\"color\":[2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"showlegend\":false,\"x\":[0.05600082595445708,0.20872059413142438,0.3416167447561173,0.08017040595296564,0.07899064077636858,0.050262831329640406,0.17135410419147884,0.33805534448243385,0.32029305321557017,0.05370304624089107,0.10126536910419875,0.23652851763852023,0.12150408534422823,0.25289735495023613,0.1507525864244243,0.07060265665848744,0.3933395823393196,0.10571116619000896,0.18073945384476767,0.13084103277741746,0.2777437196280332,0.19490599902185854,0.15828499449448916,0.28412064390880887,0.18445681042661144,0.10622625028067424,0.23342727378647213,0.06364142060495327,0.09210568236571967,0.05944201683712933],\"y\":[0.7951908122787738,0.7916691687997688,0.7952277949435803,0.7948874231767353,0.7918008531201574,0.7957592445039456,0.7957028249674201,0.7908866467307051,0.7959791628486299,0.7963595289737755,0.7923682709821112,0.7935965942744176,0.7953166252716038,0.7937700408037158,0.794621492896779,0.7952832176626796,0.7948003152072503,0.7918306988857373,0.7958892403670812,0.7915139629264304,0.7946765310227036,0.7939787749138371,0.7940949518296788,0.7926102922050962,0.7953588410408238,0.7936016328457576,0.7948219001707948,0.7942319457948611,0.7942030689600568,0.7966013353076016],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"marker\":{\"color\":[2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"showlegend\":false,\"x\":[0.024191187170021586,0.07184867601222965,0.03553829607095776,0.06691894060876453,0.09181969501599369,0.0241325840947667,0.015639011733070828,0.0785130254984566,0.02550126919582656,0.05110780291361459,0.1274569941883908,0.03864900197459376,0.01042032422206437,0.0447571019559725,0.024938106100972076,0.04700569078882467,0.017946701916371828,0.057062670823007505,0.033012733246943114,0.13933307576748083,0.01571752404017651,0.03173682895520781,0.028947940431367114,0.049644162883502416,0.01941428639545537,0.03871191335874485,0.01122046729481256,0.029285419322983595,0.057761295076003735,0.022770370427204846],\"y\":[0.7951908122787738,0.7916691687997688,0.7952277949435803,0.7948874231767353,0.7918008531201574,0.7957592445039456,0.7957028249674201,0.7908866467307051,0.7959791628486299,0.7963595289737755,0.7923682709821112,0.7935965942744176,0.7953166252716038,0.7937700408037158,0.794621492896779,0.7952832176626796,0.7948003152072503,0.7918306988857373,0.7958892403670812,0.7915139629264304,0.7946765310227036,0.7939787749138371,0.7940949518296788,0.7926102922050962,0.7953588410408238,0.7936016328457576,0.7948219001707948,0.7942319457948611,0.7942030689600568,0.7966013353076016],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"marker\":{\"color\":[2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"showlegend\":false,\"x\":[120,90,70,60,100,120,100,60,90,100,80,100,90,110,80,110,80,110,90,90,70,100,90,90,80,100,110,70,90,120],\"y\":[0.7951908122787738,0.7916691687997688,0.7952277949435803,0.7948874231767353,0.7918008531201574,0.7957592445039456,0.7957028249674201,0.7908866467307051,0.7959791628486299,0.7963595289737755,0.7923682709821112,0.7935965942744176,0.7953166252716038,0.7937700408037158,0.794621492896779,0.7952832176626796,0.7948003152072503,0.7918306988857373,0.7958892403670812,0.7915139629264304,0.7946765310227036,0.7939787749138371,0.7940949518296788,0.7926102922050962,0.7953588410408238,0.7936016328457576,0.7948219001707948,0.7942319457948611,0.7942030689600568,0.7966013353076016],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"marker\":{\"color\":[2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"showlegend\":false,\"x\":[70,90,110,110,60,120,110,60,70,100,90,80,80,100,80,100,70,100,70,120,90,70,60,70,80,90,70,100,80,60],\"y\":[0.7951908122787738,0.7916691687997688,0.7952277949435803,0.7948874231767353,0.7918008531201574,0.7957592445039456,0.7957028249674201,0.7908866467307051,0.7959791628486299,0.7963595289737755,0.7923682709821112,0.7935965942744176,0.7953166252716038,0.7937700408037158,0.794621492896779,0.7952832176626796,0.7948003152072503,0.7918306988857373,0.7958892403670812,0.7915139629264304,0.7946765310227036,0.7939787749138371,0.7940949518296788,0.7926102922050962,0.7953588410408238,0.7936016328457576,0.7948219001707948,0.7942319457948611,0.7942030689600568,0.7966013353076016],\"type\":\"scatter\",\"xaxis\":\"x5\",\"yaxis\":\"y5\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.16799999999999998],\"title\":{\"text\":\"bagging_fraction\"},\"type\":\"log\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Objective Value\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.208,0.376],\"title\":{\"text\":\"feature_fraction\"},\"type\":\"log\"},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.416,0.584],\"title\":{\"text\":\"learning_rate\"},\"type\":\"log\"},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.624,0.792],\"title\":{\"text\":\"min_data_in_leaf\"}},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis5\":{\"anchor\":\"y5\",\"domain\":[0.832,1.0],\"title\":{\"text\":\"num_leaves\"}},\"yaxis5\":{\"anchor\":\"x5\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"title\":{\"text\":\"Slice Plot\"},\"width\":1500},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('7edf564c-7a0a-4eee-96c9-27cb4202d19f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create the summary dataframe for trial results and parameter values\n",
        "df = study.trials_dataframe()\n",
        "values=[]\n",
        "i=0\n",
        "while True:\n",
        "  try:\n",
        "    values.append(study.get_trials()[i].value)\n",
        "    i+=1\n",
        "  except: break\n",
        "cols=[ 'params_bagging_fraction', 'params_feature_fraction',\n",
        "       'params_learning_rate', 'params_min_data_in_leaf', 'params_num_leaves','value']\n",
        "result=df[df.value>0.795][cols]\n",
        "result.columns=['bag','feat','l_rate','min_d_leaf','num_leaves','value']\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "tq9ospJKBRmL",
        "outputId": "38470ef2-831a-48f1-a0f8-b405419776f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         bag      feat    l_rate  min_d_leaf  num_leaves     value\n",
              "2   0.787915  0.056001  0.024191         120          70  0.795191\n",
              "4   0.675756  0.341617  0.035538          70         110  0.795228\n",
              "7   0.541996  0.050263  0.024133         120         120  0.795759\n",
              "8   0.413862  0.171354  0.015639         100         110  0.795703\n",
              "10  0.584066  0.320293  0.025501          90          70  0.795979\n",
              "11  0.465851  0.053703  0.051108         100         100  0.796360\n",
              "14  0.589056  0.121504  0.010420          90          80  0.795317\n",
              "17  0.530753  0.070603  0.047006         110         100  0.795283\n",
              "20  0.531459  0.180739  0.033013          90          70  0.795889\n",
              "26  0.437348  0.184457  0.019414          80          80  0.795359\n",
              "31  0.459187  0.059442  0.022770         120          60  0.796601"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b6feeb9e-fd63-4f06-af87-7e94b1c27985\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bag</th>\n",
              "      <th>feat</th>\n",
              "      <th>l_rate</th>\n",
              "      <th>min_d_leaf</th>\n",
              "      <th>num_leaves</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.787915</td>\n",
              "      <td>0.056001</td>\n",
              "      <td>0.024191</td>\n",
              "      <td>120</td>\n",
              "      <td>70</td>\n",
              "      <td>0.795191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.675756</td>\n",
              "      <td>0.341617</td>\n",
              "      <td>0.035538</td>\n",
              "      <td>70</td>\n",
              "      <td>110</td>\n",
              "      <td>0.795228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.541996</td>\n",
              "      <td>0.050263</td>\n",
              "      <td>0.024133</td>\n",
              "      <td>120</td>\n",
              "      <td>120</td>\n",
              "      <td>0.795759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.413862</td>\n",
              "      <td>0.171354</td>\n",
              "      <td>0.015639</td>\n",
              "      <td>100</td>\n",
              "      <td>110</td>\n",
              "      <td>0.795703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.584066</td>\n",
              "      <td>0.320293</td>\n",
              "      <td>0.025501</td>\n",
              "      <td>90</td>\n",
              "      <td>70</td>\n",
              "      <td>0.795979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.465851</td>\n",
              "      <td>0.053703</td>\n",
              "      <td>0.051108</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>0.796360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.589056</td>\n",
              "      <td>0.121504</td>\n",
              "      <td>0.010420</td>\n",
              "      <td>90</td>\n",
              "      <td>80</td>\n",
              "      <td>0.795317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.530753</td>\n",
              "      <td>0.070603</td>\n",
              "      <td>0.047006</td>\n",
              "      <td>110</td>\n",
              "      <td>100</td>\n",
              "      <td>0.795283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.531459</td>\n",
              "      <td>0.180739</td>\n",
              "      <td>0.033013</td>\n",
              "      <td>90</td>\n",
              "      <td>70</td>\n",
              "      <td>0.795889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.437348</td>\n",
              "      <td>0.184457</td>\n",
              "      <td>0.019414</td>\n",
              "      <td>80</td>\n",
              "      <td>80</td>\n",
              "      <td>0.795359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.459187</td>\n",
              "      <td>0.059442</td>\n",
              "      <td>0.022770</td>\n",
              "      <td>120</td>\n",
              "      <td>60</td>\n",
              "      <td>0.796601</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b6feeb9e-fd63-4f06-af87-7e94b1c27985')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b6feeb9e-fd63-4f06-af87-7e94b1c27985 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b6feeb9e-fd63-4f06-af87-7e94b1c27985');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SECOND TUNING\n",
        "def objective(trial):\n",
        "    # \n",
        "    param={\n",
        "          'objective':'binary',\n",
        "          # 'metric':'binary_logloss',\n",
        "          # 'verbosity':-1,\n",
        "          # 'boosting_type':'dart',\n",
        "          \"bagging_fraction\": trial.suggest_loguniform(\"bagging_fraction\", 0.4, 0.6),\n",
        "          # \"max_depth\": trial.suggest_int(\"max_depth\", 15, 40,5),\n",
        "          \"num_leaves\": trial.suggest_int(\"num_leaves\", 30, 70,10),\n",
        "          \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.005, 0.025),\n",
        "          # \"bagging_freq\": trial.suggest_categorical(\"bagging_freq\", [10]),\n",
        "          \"feature_fraction\": trial.suggest_loguniform(\"feature_fraction\", 0.03, 0.07), # increase the upper bound for the next round of\n",
        "          # 'feature_fraction_bynode':trial.suggest_loguniform(\"feature_fraction_bynode\", 0.3, 0.90), \n",
        "          \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 100, 400, 25),\n",
        "          \"metric\": \"None\",\n",
        "          \"first_metric_only\": True,\n",
        "          \"seed\": 50\n",
        "            }\n",
        "    # run model     \n",
        "\n",
        "    lgb_train = lgb.Dataset(x_train, label=y_train,\n",
        "                         free_raw_data=False)\n",
        "    lgb_eval = lgb.Dataset(x_val, label=y_val, reference=lgb_train,\n",
        "                        free_raw_data=False)\n",
        "    \n",
        "    gbm = lgb.train(param,\n",
        "                    num_boost_round=15000,\n",
        "                    train_set=lgb_train,\n",
        "                    valid_sets=[lgb_eval,lgb_train],\n",
        "                    feval=amex,\n",
        "                    early_stopping_rounds=5000,\n",
        "                    verbose_eval=200\n",
        "                    )\n",
        "\n",
        "    cv_score=gbm.best_score['valid_0']['amex']\n",
        "    return cv_score\n",
        "\n",
        "# Suppress information only outputs\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "study_name = \"example-study-long\"  # Unique identifier of the study.\n",
        "storage_name = \"sqlite:///{}.db\".format(study_name)\n",
        "study = optuna.create_study(direction='maximize',study_name=study_name, storage=storage_name,load_if_exists=True)\n",
        "study.optimize(objective,timeout=7200)"
      ],
      "metadata": {
        "id": "-ddmSCP4BRxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "lgb_train = lgb.Dataset(x_train, label=y_train,\n",
        "                         free_raw_data=False)\n",
        "lgb_eval = lgb.Dataset(x_val, label=y_val, reference=lgb_train,\n",
        "                        free_raw_data=False)\n",
        "\n",
        "params={\n",
        "  'objective':'binary',\n",
        "  'metric':'cross_entrophy',\n",
        "  'tree_learner':'voting',\n",
        "  'is_unbalance':True,\n",
        "  'boosting':'goss',\n",
        "  'bagging_fraction': 0.46,\n",
        " 'feature_fraction': 0.06,\n",
        "  'learning_rate': 0.0215,\n",
        " 'min_data_in_leaf': 120,\n",
        " 'num_leaves': 60,\n",
        " 'seed': 123}\n",
        "\n",
        "gbm2 = lgb.train(   params, \n",
        "                    num_boost_round=9999,\n",
        "                    train_set=lgb_train,\n",
        "                    valid_sets=[lgb_eval,lgb_train],\n",
        "                    feval=amex,\n",
        "                    early_stopping_rounds=4500, verbose_eval=50 #,callbacks=[lgb.reset_parameter(learning_rate=learning_rate_decay)]\n",
        "                    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTkJvFUMorE9",
        "outputId": "65741bc7-0b24-4bb3-943e-352aaaaf41e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 4500 rounds.\n",
            "[50]\ttraining's binary_logloss: 0.355721\ttraining's amex: 0.765501\tvalid_0's binary_logloss: 0.35924\tvalid_0's amex: 0.760253\n",
            "[100]\ttraining's binary_logloss: 0.282091\ttraining's amex: 0.773606\tvalid_0's binary_logloss: 0.286527\tvalid_0's amex: 0.766438\n",
            "[150]\ttraining's binary_logloss: 0.25036\ttraining's amex: 0.779694\tvalid_0's binary_logloss: 0.255785\tvalid_0's amex: 0.770665\n",
            "[200]\ttraining's binary_logloss: 0.234775\ttraining's amex: 0.784783\tvalid_0's binary_logloss: 0.241282\tvalid_0's amex: 0.775187\n",
            "[250]\ttraining's binary_logloss: 0.226227\ttraining's amex: 0.789345\tvalid_0's binary_logloss: 0.233861\tvalid_0's amex: 0.778086\n",
            "[300]\ttraining's binary_logloss: 0.220735\ttraining's amex: 0.793768\tvalid_0's binary_logloss: 0.229588\tvalid_0's amex: 0.779958\n",
            "[350]\ttraining's binary_logloss: 0.216852\ttraining's amex: 0.797312\tvalid_0's binary_logloss: 0.226928\tvalid_0's amex: 0.783194\n",
            "[400]\ttraining's binary_logloss: 0.213842\ttraining's amex: 0.80039\tvalid_0's binary_logloss: 0.225189\tvalid_0's amex: 0.785176\n",
            "[450]\ttraining's binary_logloss: 0.211281\ttraining's amex: 0.803592\tvalid_0's binary_logloss: 0.223843\tvalid_0's amex: 0.787908\n",
            "[500]\ttraining's binary_logloss: 0.209003\ttraining's amex: 0.80631\tvalid_0's binary_logloss: 0.222855\tvalid_0's amex: 0.789198\n",
            "[550]\ttraining's binary_logloss: 0.20694\ttraining's amex: 0.808666\tvalid_0's binary_logloss: 0.222143\tvalid_0's amex: 0.789713\n",
            "[600]\ttraining's binary_logloss: 0.20504\ttraining's amex: 0.810959\tvalid_0's binary_logloss: 0.221567\tvalid_0's amex: 0.789991\n",
            "[650]\ttraining's binary_logloss: 0.203239\ttraining's amex: 0.813551\tvalid_0's binary_logloss: 0.221132\tvalid_0's amex: 0.790024\n",
            "[700]\ttraining's binary_logloss: 0.201537\ttraining's amex: 0.816156\tvalid_0's binary_logloss: 0.220732\tvalid_0's amex: 0.790149\n",
            "[750]\ttraining's binary_logloss: 0.199903\ttraining's amex: 0.818368\tvalid_0's binary_logloss: 0.220407\tvalid_0's amex: 0.790842\n",
            "[800]\ttraining's binary_logloss: 0.198335\ttraining's amex: 0.820569\tvalid_0's binary_logloss: 0.22014\tvalid_0's amex: 0.790839\n",
            "[850]\ttraining's binary_logloss: 0.196809\ttraining's amex: 0.822601\tvalid_0's binary_logloss: 0.219859\tvalid_0's amex: 0.790789\n",
            "[900]\ttraining's binary_logloss: 0.195336\ttraining's amex: 0.824816\tvalid_0's binary_logloss: 0.21966\tvalid_0's amex: 0.791208\n",
            "[950]\ttraining's binary_logloss: 0.193883\ttraining's amex: 0.827036\tvalid_0's binary_logloss: 0.21948\tvalid_0's amex: 0.79131\n",
            "[1000]\ttraining's binary_logloss: 0.192466\ttraining's amex: 0.82939\tvalid_0's binary_logloss: 0.219282\tvalid_0's amex: 0.791385\n",
            "[1050]\ttraining's binary_logloss: 0.191101\ttraining's amex: 0.831464\tvalid_0's binary_logloss: 0.219086\tvalid_0's amex: 0.791723\n",
            "[1100]\ttraining's binary_logloss: 0.189735\ttraining's amex: 0.833418\tvalid_0's binary_logloss: 0.218924\tvalid_0's amex: 0.792192\n",
            "[1150]\ttraining's binary_logloss: 0.188414\ttraining's amex: 0.835677\tvalid_0's binary_logloss: 0.218785\tvalid_0's amex: 0.792372\n",
            "[1200]\ttraining's binary_logloss: 0.187085\ttraining's amex: 0.837973\tvalid_0's binary_logloss: 0.218695\tvalid_0's amex: 0.792609\n",
            "[1250]\ttraining's binary_logloss: 0.185802\ttraining's amex: 0.840064\tvalid_0's binary_logloss: 0.218649\tvalid_0's amex: 0.792639\n",
            "[1300]\ttraining's binary_logloss: 0.184513\ttraining's amex: 0.842352\tvalid_0's binary_logloss: 0.218523\tvalid_0's amex: 0.793079\n",
            "[1350]\ttraining's binary_logloss: 0.183245\ttraining's amex: 0.844433\tvalid_0's binary_logloss: 0.21846\tvalid_0's amex: 0.792702\n",
            "[1400]\ttraining's binary_logloss: 0.182022\ttraining's amex: 0.846531\tvalid_0's binary_logloss: 0.218363\tvalid_0's amex: 0.792739\n",
            "[1450]\ttraining's binary_logloss: 0.180803\ttraining's amex: 0.848844\tvalid_0's binary_logloss: 0.218304\tvalid_0's amex: 0.792736\n",
            "[1500]\ttraining's binary_logloss: 0.179594\ttraining's amex: 0.851074\tvalid_0's binary_logloss: 0.218241\tvalid_0's amex: 0.793051\n",
            "[1550]\ttraining's binary_logloss: 0.178407\ttraining's amex: 0.853349\tvalid_0's binary_logloss: 0.218195\tvalid_0's amex: 0.792883\n",
            "[1600]\ttraining's binary_logloss: 0.177225\ttraining's amex: 0.855579\tvalid_0's binary_logloss: 0.218134\tvalid_0's amex: 0.793261\n",
            "[1650]\ttraining's binary_logloss: 0.17609\ttraining's amex: 0.857453\tvalid_0's binary_logloss: 0.218113\tvalid_0's amex: 0.793352\n",
            "[1700]\ttraining's binary_logloss: 0.174951\ttraining's amex: 0.859504\tvalid_0's binary_logloss: 0.218072\tvalid_0's amex: 0.793091\n",
            "[1750]\ttraining's binary_logloss: 0.173818\ttraining's amex: 0.861755\tvalid_0's binary_logloss: 0.218023\tvalid_0's amex: 0.79292\n",
            "[1800]\ttraining's binary_logloss: 0.172703\ttraining's amex: 0.863613\tvalid_0's binary_logloss: 0.217983\tvalid_0's amex: 0.793519\n",
            "[1850]\ttraining's binary_logloss: 0.171586\ttraining's amex: 0.865738\tvalid_0's binary_logloss: 0.21793\tvalid_0's amex: 0.793162\n",
            "[1900]\ttraining's binary_logloss: 0.170491\ttraining's amex: 0.867874\tvalid_0's binary_logloss: 0.217891\tvalid_0's amex: 0.793178\n",
            "[1950]\ttraining's binary_logloss: 0.169423\ttraining's amex: 0.869702\tvalid_0's binary_logloss: 0.217857\tvalid_0's amex: 0.793899\n",
            "[2000]\ttraining's binary_logloss: 0.168363\ttraining's amex: 0.871407\tvalid_0's binary_logloss: 0.217828\tvalid_0's amex: 0.793452\n",
            "[2050]\ttraining's binary_logloss: 0.167298\ttraining's amex: 0.873462\tvalid_0's binary_logloss: 0.217805\tvalid_0's amex: 0.793859\n",
            "[2100]\ttraining's binary_logloss: 0.16624\ttraining's amex: 0.875305\tvalid_0's binary_logloss: 0.217777\tvalid_0's amex: 0.793995\n",
            "[2150]\ttraining's binary_logloss: 0.165201\ttraining's amex: 0.877241\tvalid_0's binary_logloss: 0.217749\tvalid_0's amex: 0.794026\n",
            "[2200]\ttraining's binary_logloss: 0.16417\ttraining's amex: 0.879016\tvalid_0's binary_logloss: 0.217748\tvalid_0's amex: 0.793777\n",
            "[2250]\ttraining's binary_logloss: 0.163153\ttraining's amex: 0.880878\tvalid_0's binary_logloss: 0.217726\tvalid_0's amex: 0.794034\n",
            "[2300]\ttraining's binary_logloss: 0.162137\ttraining's amex: 0.88289\tvalid_0's binary_logloss: 0.217685\tvalid_0's amex: 0.794383\n",
            "[2350]\ttraining's binary_logloss: 0.16115\ttraining's amex: 0.884576\tvalid_0's binary_logloss: 0.217666\tvalid_0's amex: 0.794639\n",
            "[2400]\ttraining's binary_logloss: 0.160158\ttraining's amex: 0.886388\tvalid_0's binary_logloss: 0.21767\tvalid_0's amex: 0.793863\n",
            "[2450]\ttraining's binary_logloss: 0.159188\ttraining's amex: 0.888327\tvalid_0's binary_logloss: 0.217659\tvalid_0's amex: 0.794347\n",
            "[2500]\ttraining's binary_logloss: 0.158221\ttraining's amex: 0.890254\tvalid_0's binary_logloss: 0.217661\tvalid_0's amex: 0.794179\n",
            "[2550]\ttraining's binary_logloss: 0.157249\ttraining's amex: 0.89192\tvalid_0's binary_logloss: 0.217641\tvalid_0's amex: 0.794043\n",
            "[2600]\ttraining's binary_logloss: 0.1563\ttraining's amex: 0.893765\tvalid_0's binary_logloss: 0.21761\tvalid_0's amex: 0.79418\n",
            "[2650]\ttraining's binary_logloss: 0.15537\ttraining's amex: 0.895561\tvalid_0's binary_logloss: 0.217615\tvalid_0's amex: 0.793825\n",
            "[2700]\ttraining's binary_logloss: 0.154434\ttraining's amex: 0.897308\tvalid_0's binary_logloss: 0.21761\tvalid_0's amex: 0.794119\n",
            "[2750]\ttraining's binary_logloss: 0.15351\ttraining's amex: 0.898916\tvalid_0's binary_logloss: 0.217607\tvalid_0's amex: 0.79427\n",
            "[2800]\ttraining's binary_logloss: 0.152585\ttraining's amex: 0.900712\tvalid_0's binary_logloss: 0.217583\tvalid_0's amex: 0.794634\n",
            "[2850]\ttraining's binary_logloss: 0.151679\ttraining's amex: 0.902245\tvalid_0's binary_logloss: 0.217565\tvalid_0's amex: 0.794684\n",
            "[2900]\ttraining's binary_logloss: 0.15077\ttraining's amex: 0.90376\tvalid_0's binary_logloss: 0.217531\tvalid_0's amex: 0.795115\n",
            "[2950]\ttraining's binary_logloss: 0.149888\ttraining's amex: 0.905487\tvalid_0's binary_logloss: 0.217537\tvalid_0's amex: 0.79453\n",
            "[3000]\ttraining's binary_logloss: 0.149005\ttraining's amex: 0.907144\tvalid_0's binary_logloss: 0.217534\tvalid_0's amex: 0.795095\n",
            "[3050]\ttraining's binary_logloss: 0.148124\ttraining's amex: 0.908873\tvalid_0's binary_logloss: 0.21753\tvalid_0's amex: 0.794951\n",
            "[3100]\ttraining's binary_logloss: 0.147249\ttraining's amex: 0.910456\tvalid_0's binary_logloss: 0.217528\tvalid_0's amex: 0.794429\n",
            "[3150]\ttraining's binary_logloss: 0.146389\ttraining's amex: 0.91195\tvalid_0's binary_logloss: 0.217549\tvalid_0's amex: 0.794298\n",
            "[3200]\ttraining's binary_logloss: 0.14554\ttraining's amex: 0.913544\tvalid_0's binary_logloss: 0.217536\tvalid_0's amex: 0.794095\n",
            "[3250]\ttraining's binary_logloss: 0.144687\ttraining's amex: 0.914849\tvalid_0's binary_logloss: 0.217507\tvalid_0's amex: 0.793877\n",
            "[3300]\ttraining's binary_logloss: 0.143841\ttraining's amex: 0.91641\tvalid_0's binary_logloss: 0.217506\tvalid_0's amex: 0.794191\n",
            "[3350]\ttraining's binary_logloss: 0.14302\ttraining's amex: 0.917719\tvalid_0's binary_logloss: 0.217497\tvalid_0's amex: 0.794256\n",
            "[3400]\ttraining's binary_logloss: 0.142188\ttraining's amex: 0.919318\tvalid_0's binary_logloss: 0.217475\tvalid_0's amex: 0.794205\n",
            "[3450]\ttraining's binary_logloss: 0.141359\ttraining's amex: 0.92079\tvalid_0's binary_logloss: 0.217465\tvalid_0's amex: 0.794315\n",
            "[3500]\ttraining's binary_logloss: 0.140543\ttraining's amex: 0.922354\tvalid_0's binary_logloss: 0.217443\tvalid_0's amex: 0.794554\n",
            "[3550]\ttraining's binary_logloss: 0.13973\ttraining's amex: 0.923729\tvalid_0's binary_logloss: 0.217448\tvalid_0's amex: 0.794596\n",
            "[3600]\ttraining's binary_logloss: 0.138923\ttraining's amex: 0.925017\tvalid_0's binary_logloss: 0.217441\tvalid_0's amex: 0.794578\n",
            "[3650]\ttraining's binary_logloss: 0.138124\ttraining's amex: 0.926432\tvalid_0's binary_logloss: 0.21743\tvalid_0's amex: 0.794708\n",
            "[3700]\ttraining's binary_logloss: 0.137335\ttraining's amex: 0.927715\tvalid_0's binary_logloss: 0.217453\tvalid_0's amex: 0.794556\n",
            "[3750]\ttraining's binary_logloss: 0.136541\ttraining's amex: 0.928906\tvalid_0's binary_logloss: 0.217473\tvalid_0's amex: 0.794238\n",
            "[3800]\ttraining's binary_logloss: 0.135762\ttraining's amex: 0.93028\tvalid_0's binary_logloss: 0.217493\tvalid_0's amex: 0.794276\n",
            "[3850]\ttraining's binary_logloss: 0.134988\ttraining's amex: 0.931424\tvalid_0's binary_logloss: 0.217506\tvalid_0's amex: 0.794503\n",
            "[3900]\ttraining's binary_logloss: 0.134218\ttraining's amex: 0.932861\tvalid_0's binary_logloss: 0.217522\tvalid_0's amex: 0.794773\n",
            "[3950]\ttraining's binary_logloss: 0.133442\ttraining's amex: 0.934104\tvalid_0's binary_logloss: 0.217532\tvalid_0's amex: 0.794605\n",
            "[4000]\ttraining's binary_logloss: 0.132682\ttraining's amex: 0.935503\tvalid_0's binary_logloss: 0.217514\tvalid_0's amex: 0.794782\n",
            "[4050]\ttraining's binary_logloss: 0.131926\ttraining's amex: 0.936642\tvalid_0's binary_logloss: 0.217519\tvalid_0's amex: 0.794743\n",
            "[4100]\ttraining's binary_logloss: 0.131183\ttraining's amex: 0.937899\tvalid_0's binary_logloss: 0.217549\tvalid_0's amex: 0.794755\n",
            "[4150]\ttraining's binary_logloss: 0.130437\ttraining's amex: 0.939099\tvalid_0's binary_logloss: 0.217538\tvalid_0's amex: 0.794489\n",
            "[4200]\ttraining's binary_logloss: 0.1297\ttraining's amex: 0.940207\tvalid_0's binary_logloss: 0.217541\tvalid_0's amex: 0.794826\n",
            "[4250]\ttraining's binary_logloss: 0.128962\ttraining's amex: 0.941365\tvalid_0's binary_logloss: 0.217546\tvalid_0's amex: 0.794243\n",
            "[4300]\ttraining's binary_logloss: 0.128231\ttraining's amex: 0.942701\tvalid_0's binary_logloss: 0.217544\tvalid_0's amex: 0.794122\n",
            "[4350]\ttraining's binary_logloss: 0.127495\ttraining's amex: 0.943678\tvalid_0's binary_logloss: 0.217552\tvalid_0's amex: 0.794207\n",
            "[4400]\ttraining's binary_logloss: 0.126781\ttraining's amex: 0.944888\tvalid_0's binary_logloss: 0.21755\tvalid_0's amex: 0.794505\n",
            "[4450]\ttraining's binary_logloss: 0.12606\ttraining's amex: 0.946118\tvalid_0's binary_logloss: 0.217541\tvalid_0's amex: 0.794177\n",
            "[4500]\ttraining's binary_logloss: 0.12535\ttraining's amex: 0.947225\tvalid_0's binary_logloss: 0.21756\tvalid_0's amex: 0.794278\n",
            "[4550]\ttraining's binary_logloss: 0.12466\ttraining's amex: 0.948153\tvalid_0's binary_logloss: 0.217558\tvalid_0's amex: 0.794431\n",
            "[4600]\ttraining's binary_logloss: 0.123971\ttraining's amex: 0.949194\tvalid_0's binary_logloss: 0.217571\tvalid_0's amex: 0.794034\n",
            "[4650]\ttraining's binary_logloss: 0.123272\ttraining's amex: 0.950262\tvalid_0's binary_logloss: 0.217588\tvalid_0's amex: 0.79447\n",
            "[4700]\ttraining's binary_logloss: 0.122586\ttraining's amex: 0.951328\tvalid_0's binary_logloss: 0.217601\tvalid_0's amex: 0.793991\n",
            "[4750]\ttraining's binary_logloss: 0.121898\ttraining's amex: 0.952268\tvalid_0's binary_logloss: 0.217629\tvalid_0's amex: 0.793841\n",
            "[4800]\ttraining's binary_logloss: 0.121212\ttraining's amex: 0.953314\tvalid_0's binary_logloss: 0.217644\tvalid_0's amex: 0.79407\n",
            "[4850]\ttraining's binary_logloss: 0.120548\ttraining's amex: 0.954275\tvalid_0's binary_logloss: 0.217667\tvalid_0's amex: 0.79459\n",
            "[4900]\ttraining's binary_logloss: 0.119881\ttraining's amex: 0.955332\tvalid_0's binary_logloss: 0.217702\tvalid_0's amex: 0.794227\n",
            "[4950]\ttraining's binary_logloss: 0.119225\ttraining's amex: 0.95618\tvalid_0's binary_logloss: 0.217709\tvalid_0's amex: 0.794752\n",
            "[5000]\ttraining's binary_logloss: 0.118577\ttraining's amex: 0.957116\tvalid_0's binary_logloss: 0.217724\tvalid_0's amex: 0.794167\n",
            "[5050]\ttraining's binary_logloss: 0.117924\ttraining's amex: 0.958031\tvalid_0's binary_logloss: 0.217729\tvalid_0's amex: 0.793918\n",
            "[5100]\ttraining's binary_logloss: 0.11726\ttraining's amex: 0.95891\tvalid_0's binary_logloss: 0.21776\tvalid_0's amex: 0.793912\n",
            "[5150]\ttraining's binary_logloss: 0.116602\ttraining's amex: 0.959702\tvalid_0's binary_logloss: 0.217795\tvalid_0's amex: 0.794345\n",
            "[5200]\ttraining's binary_logloss: 0.115947\ttraining's amex: 0.960583\tvalid_0's binary_logloss: 0.217806\tvalid_0's amex: 0.794325\n",
            "[5250]\ttraining's binary_logloss: 0.115305\ttraining's amex: 0.961455\tvalid_0's binary_logloss: 0.217822\tvalid_0's amex: 0.794077\n",
            "[5300]\ttraining's binary_logloss: 0.114669\ttraining's amex: 0.962454\tvalid_0's binary_logloss: 0.217833\tvalid_0's amex: 0.794181\n",
            "[5350]\ttraining's binary_logloss: 0.114029\ttraining's amex: 0.963317\tvalid_0's binary_logloss: 0.217845\tvalid_0's amex: 0.793827\n",
            "[5400]\ttraining's binary_logloss: 0.1134\ttraining's amex: 0.964185\tvalid_0's binary_logloss: 0.217856\tvalid_0's amex: 0.793725\n",
            "[5450]\ttraining's binary_logloss: 0.112785\ttraining's amex: 0.964943\tvalid_0's binary_logloss: 0.21787\tvalid_0's amex: 0.794017\n",
            "[5500]\ttraining's binary_logloss: 0.112165\ttraining's amex: 0.965661\tvalid_0's binary_logloss: 0.217905\tvalid_0's amex: 0.7937\n",
            "[5550]\ttraining's binary_logloss: 0.111547\ttraining's amex: 0.966385\tvalid_0's binary_logloss: 0.217925\tvalid_0's amex: 0.793991\n",
            "[5600]\ttraining's binary_logloss: 0.110934\ttraining's amex: 0.96725\tvalid_0's binary_logloss: 0.217927\tvalid_0's amex: 0.793746\n",
            "[5650]\ttraining's binary_logloss: 0.110325\ttraining's amex: 0.968106\tvalid_0's binary_logloss: 0.217943\tvalid_0's amex: 0.793749\n",
            "[5700]\ttraining's binary_logloss: 0.109722\ttraining's amex: 0.968783\tvalid_0's binary_logloss: 0.21797\tvalid_0's amex: 0.794183\n",
            "[5750]\ttraining's binary_logloss: 0.109116\ttraining's amex: 0.969584\tvalid_0's binary_logloss: 0.21802\tvalid_0's amex: 0.794256\n",
            "[5800]\ttraining's binary_logloss: 0.108531\ttraining's amex: 0.97026\tvalid_0's binary_logloss: 0.218037\tvalid_0's amex: 0.794322\n",
            "[5850]\ttraining's binary_logloss: 0.107939\ttraining's amex: 0.970989\tvalid_0's binary_logloss: 0.218075\tvalid_0's amex: 0.794503\n",
            "[5900]\ttraining's binary_logloss: 0.107365\ttraining's amex: 0.971635\tvalid_0's binary_logloss: 0.2181\tvalid_0's amex: 0.794145\n",
            "[5950]\ttraining's binary_logloss: 0.106778\ttraining's amex: 0.972441\tvalid_0's binary_logloss: 0.21813\tvalid_0's amex: 0.793765\n",
            "[6000]\ttraining's binary_logloss: 0.106199\ttraining's amex: 0.972958\tvalid_0's binary_logloss: 0.218148\tvalid_0's amex: 0.794224\n",
            "[6050]\ttraining's binary_logloss: 0.10562\ttraining's amex: 0.973652\tvalid_0's binary_logloss: 0.218176\tvalid_0's amex: 0.794349\n",
            "[6100]\ttraining's binary_logloss: 0.105061\ttraining's amex: 0.974364\tvalid_0's binary_logloss: 0.2182\tvalid_0's amex: 0.794389\n",
            "[6150]\ttraining's binary_logloss: 0.10448\ttraining's amex: 0.975032\tvalid_0's binary_logloss: 0.21823\tvalid_0's amex: 0.794303\n",
            "[6200]\ttraining's binary_logloss: 0.103903\ttraining's amex: 0.975683\tvalid_0's binary_logloss: 0.218256\tvalid_0's amex: 0.794237\n",
            "[6250]\ttraining's binary_logloss: 0.103336\ttraining's amex: 0.976357\tvalid_0's binary_logloss: 0.218299\tvalid_0's amex: 0.794377\n",
            "[6300]\ttraining's binary_logloss: 0.102773\ttraining's amex: 0.976866\tvalid_0's binary_logloss: 0.218309\tvalid_0's amex: 0.794401\n",
            "[6350]\ttraining's binary_logloss: 0.102219\ttraining's amex: 0.97751\tvalid_0's binary_logloss: 0.218332\tvalid_0's amex: 0.794341\n",
            "[6400]\ttraining's binary_logloss: 0.101663\ttraining's amex: 0.978112\tvalid_0's binary_logloss: 0.218362\tvalid_0's amex: 0.794298\n",
            "[6450]\ttraining's binary_logloss: 0.10111\ttraining's amex: 0.978802\tvalid_0's binary_logloss: 0.218375\tvalid_0's amex: 0.794197\n",
            "[6500]\ttraining's binary_logloss: 0.100553\ttraining's amex: 0.979373\tvalid_0's binary_logloss: 0.218394\tvalid_0's amex: 0.794305\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[6500]\ttraining's binary_logloss: 0.100553\ttraining's amex: 0.979373\tvalid_0's binary_logloss: 0.218394\tvalid_0's amex: 0.794305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- <!-- # def learning_rate_decay(current_iter):\n",
        "#     base_learning_rate = 0.04\n",
        "#     lr = base_learning_rate  * np.power(.9999, current_iter)\n",
        "#     return lr if lr > 0.005 else 0.005 -->\n",
        "<!-- \n",
        "tree_learner=voting\n",
        "\n",
        "is_unbalance=True\n",
        "\n",
        "sigmoid=1 #default\n",
        "\n",
        "metric=cross_entropy --> -->\n"
      ],
      "metadata": {
        "id": "6TVK2u8Ga8-3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QT4YxdwrKjLm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}